{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to EnergyFlow EnergyFlow is a Python package for computing Energy Flow Polynomials (EFPs), a collection of jet substructure observables which form a complete linear basis of IRC-safe observables, and for implementing Energy Flow Networks (EFNs) and Particle Flow Networks (PFNs). We also provide quick implementations of other architectures useful for particle physics, namely convolutional neural networks (CNNs) for jet images and dense neural networks (DNNs) for e.g. the $N$-subjettiness phase space basis. The current version is 0.10.3 . We recommend that you use the most up-to-date version as things may change quickly. As of version 0.7.0 , tests have been written covering the majority of the EFP code. The source code can be found on GitHub . Get started by installing EnergyFlow , exploring the demo , and running the examples ! References [1] P. T. Komiske, E. M. Metodiev, and J. Thaler, Energy Flow Polynomials: A complete linear basis for jet substructure , JHEP 04 (2018) 013 [ 1712.07124 ]. [2] P. T. Komiske, E. M. Metodiev, and J. Thaler, Energy Flow Networks: Deep Sets for Particle Jets , to appear soon. Copyright See the LICENSE for detailed copyright information. EnergyFlow uses a customized einsumfunc.py from the NumPy GitHub repository as well as a few functions relating to downloading files copied from the Keras GitHub repository. The copyrights for these parts of the code are properly attributed to their respective owners in the LICENSE file.","title":"Home"},{"location":"#welcome-to-energyflow","text":"EnergyFlow is a Python package for computing Energy Flow Polynomials (EFPs), a collection of jet substructure observables which form a complete linear basis of IRC-safe observables, and for implementing Energy Flow Networks (EFNs) and Particle Flow Networks (PFNs). We also provide quick implementations of other architectures useful for particle physics, namely convolutional neural networks (CNNs) for jet images and dense neural networks (DNNs) for e.g. the $N$-subjettiness phase space basis. The current version is 0.10.3 . We recommend that you use the most up-to-date version as things may change quickly. As of version 0.7.0 , tests have been written covering the majority of the EFP code. The source code can be found on GitHub . Get started by installing EnergyFlow , exploring the demo , and running the examples !","title":"Welcome to EnergyFlow"},{"location":"#references","text":"[1] P. T. Komiske, E. M. Metodiev, and J. Thaler, Energy Flow Polynomials: A complete linear basis for jet substructure , JHEP 04 (2018) 013 [ 1712.07124 ]. [2] P. T. Komiske, E. M. Metodiev, and J. Thaler, Energy Flow Networks: Deep Sets for Particle Jets , to appear soon.","title":"References"},{"location":"#copyright","text":"See the LICENSE for detailed copyright information. EnergyFlow uses a customized einsumfunc.py from the NumPy GitHub repository as well as a few functions relating to downloading files copied from the Keras GitHub repository. The copyrights for these parts of the code are properly attributed to their respective owners in the LICENSE file.","title":"Copyright"},{"location":"examples/","text":"There are currently 5 examples provided for the EnergyFlow package. They currently focus on demonstrating the various architectures included as part of EnergyFlow (see Architectures ). For an example of using the core functionality to compute EFPs, see the tutorial . To install the examples to the default directory, ~/.energyflow/examples/ , simply run python -c \"import energyflow; energyflow.utils.get_examples()\" See the get_examples function for more detailed information. cnn_example.py An example involving jet images and convolutional neural networks (CNNs). The CNN class is used to provide a network architecture based on that described in 1612.01551 . Jet images are constructed using the pixelate function and can be either one-channel (grayscale), meaning that only $p_T$ information is used, or two-channel (color), meaning that $p_T$ information and local charged particle counts are used. The images are preprocessed by subtracting the average image in the training set and dividing by the per-pixel standard deviations, using the zero_center and standardize functions, respectively. The output of the example is a plot of the ROC curves of the CNN as well as the jet mass and constituent multiplicity observables. Note that the number of epochs is quite small because it is quite time consuming to train a CNN without a GPU (which will speed up this example immensely). # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import CNN from energyflow.datasets import qg_jets from energyflow.utils import data_split, pixelate, standardize, to_categorical, zero_center # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 100000 val_frac, test_frac = 0.1, 0.15 # image parameters R = 0.4 img_width = 2*R npix = 33 nb_chan = 2 norm = True # required network architecture parameters input_shape = (nb_chan, npix, npix) filter_sizes = [8, 4, 4] num_filters = [8, 8, 8] # very small so can run on non-GPUs in reasonable time # optional network architecture parameters dense_sizes = [50] pool_sizes = 2 # network training parameters num_epoch = 2 batch_size = 100 ################################################################################ # load data X, y = qg_jets.load(num_data=num_data) # convert labels to categorical Y = to_categorical(y, num_classes=2) print('\\n', 'Loaded quark and gluon jets') # make jet images images = np.asarray([pixelate(x, npix=npix, img_width=img_width, nb_chan=nb_chan, charged_counts_only=True, norm=norm) for x in X]) print('Done making jet images') # do train/val/test split (X_train, X_val, X_test, Y_train, Y_val, Y_test) = data_split(images, Y, val=val_frac, test=test_frac) print('Done train/val/test split') # preprocess by zero centering images and standardizing each pixel X_train, X_val, X_test = standardize(*zero_center(X_train, X_val, X_test)) print('Finished preprocessing') print('Model summary:') # build architecture hps = {'input_shape': input_shape, 'filter_sizes': filter_sizes, 'num_filters': num_filters, 'dense_sizes': dense_sizes, 'pool_sizes': pool_sizes} cnn = CNN(hps) # train model cnn.fit(X_train, Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1) # get predictions on test data preds = cnn.predict(X_test, batch_size=1000) # get ROC curve if we have sklearn if roc_curve: cnn_fp, cnn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1]) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('CNN AUC:', auc) print() # make ROC curve plot if we have matplotlib if plt: # get multiplicity and mass for comparison masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphis(x).sum(axis=0)) for x in X]) mults = np.asarray([np.count_nonzero(x[:,0]) for x in X]) mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses) mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults) # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # plot the ROC curves plt.plot(cnn_tp, 1-cnn_fp, '-', color='black', label='CNN') plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass') plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity') # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show() dnn_example.py An example involving deep, fully-connected neural networks (DNNs). The DNN class is used to construct the network architecture. The inputs are taken to be the $N$-subjettiness observables as specified as part of the phase space basis from 1704.08249 , cut off at some total number of observables. The output of the example is a plot showing the ROC curves obtained from training the DNN on different numbers of $N$-subjettiness observables. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import DNN from energyflow.datasets import qg_nsubs from energyflow.utils import data_split, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 100000 val_frac, test_frac = 0.1, 0.15 # network architecture parameters dense_sizes = (100, 100) # network training parameters num_epoch = 10 batch_size = 100 # sweep parameters num_nsubs = [1, 2, 4, 8, 16, 32] colors = ['tab:red', 'tab:orange', 'tab:olive', 'tab:green', 'tab:blue', 'tab:purple'] ################################################################################ # load data X, y = qg_nsubs.load(num_data=num_data) # convert labels to categorical Y = to_categorical(y, num_classes=2) print() print('Loaded quark and gluon jets') print('Model summary:') # train models with different numbers of nsubs as input rocs = [] for i,num_nsub in enumerate(num_nsubs): # build architecture dnn = DNN(input_dim=num_nsub, dense_sizes=dense_sizes, summary=(i==0)) # do train/val/test split (X_train, X_val, X_test, Y_train, Y_val, Y_test) = data_split(X[:,:num_nsub], Y, val=val_frac, test=test_frac) print('Done train/val/test split') # train model dnn.fit(X_train, Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1) # get predictions on test data preds = dnn.predict(X_test, batch_size=1000) # get ROC curve if we have sklearn if roc_curve: rocs.append(roc_curve(Y_test[:,1], preds[:,1])) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('{} nsubs DNN AUC:'.format(num_nsub), auc) print() # make ROC curve plot if we have matplotlib if plt: # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # iterate over the ROC curves and plot them for i in range(len(rocs)): plt.plot(rocs[i][1], 1-rocs[i][0], '-', color=colors[i], label='DNN: {} N-subs'.format(num_nsubs[i])) # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show() efn_example.py An example involving Energy Flow Networks (EFNs), which are to appear soon in a paper by P. T. Komiske, E. M. Metodiev, and J. Thaler. See this talk for a brief overview of the EFN architecture. The EFN class is used to construct the network architecture. The output of the example is a plot of the ROC curves obtained by the EFN as well as the jet mass and constituent multiplicity observables. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import EFN from energyflow.datasets import qg_jets from energyflow.utils import data_split, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 100000 val_frac, test_frac = 0.1, 0.15 # network architecture parameters ppm_sizes = (100, 100) dense_sizes = (100, 100) # network training parameters num_epoch = 5 batch_size = 100 ################################################################################ # load data X, y = qg_jets.load(num_data=num_data) # ignore pid information X = X[:,:,:3] # convert labels to categorical Y = to_categorical(y, num_classes=2) print() print('Loaded quark and gluon jets') # preprocess by centering jets and normalizing pts for x in X: mask = x[:,0] > 0 yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0) x[mask,1:3] -= yphi_avg x[mask,0] /= x[:,0].sum() print('Finished preprocessing') # do train/val/test split (z_train, z_val, z_test, p_train, p_val, p_test, Y_train, Y_val, Y_test) = data_split(X[:,:,0], X[:,:,1:], Y, val=val_frac, test=test_frac) print('Done train/val/test split') print('Model summary:') # build architecture efn = EFN(input_dim=2, ppm_sizes=ppm_sizes, dense_sizes=dense_sizes) # train model efn.fit([z_train, p_train], Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=([z_val, p_val], Y_val), verbose=1) # get predictions on test data preds = efn.predict([z_test, p_test], batch_size=1000) # get ROC curve if we have sklearn if roc_curve: efn_fp, efn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1]) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('EFN AUC:', auc) print() # make ROC curve plot if we have matplotlib if plt: # get multiplicity and mass for comparison masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphis(x).sum(axis=0)) for x in X]) mults = np.asarray([np.count_nonzero(x[:,0]) for x in X]) mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses) mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults) # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # plot the ROC curves plt.plot(efn_tp, 1-efn_fp, '-', color='black', label='EFN') plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass') plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity') # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show() efp_example.py An example involving Energy Flow Polynomials (EFPs) and a linear classifier (Fisher's Linear Discriminant by default). First, the EFPSet class is used to compute the EFPs up to the specified dmax , the default being dmax=5 . Then linear classifiers are trained for different numbers of EFPs as input, determined by taking all EFPs up to degree d with d from 1 to dmax . The output of the example is a plot of the ROC curves for the classifiers with different numbers of EFP inputs. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import LinearClassifier from energyflow.datasets import qg_jets from energyflow.utils import data_split, standardize, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 20000 test_frac = 0.2 # efp parameters dmax = 5 measure = 'hadr' beta = 0.5 # plotting colors = ['tab:red', 'tab:orange', 'tab:olive', 'tab:green', 'tab:blue'] ################################################################################ # load data X, y = qg_jets.load(num_data) print() print('Loaded quark and gluon jets') # calculate EFPs print('Calculating d <= {} EFPs for {} jets... '.format(dmax, num_data), end='') efpset = ef.EFPSet(('d<=', dmax), measure='hadr', beta=beta) masked_X = [x[x[:,0] > 0] for x in X] X = efpset.batch_compute(masked_X) print('Done') # train models with different numbers of EFPs as input rocs = [] for d in range(1, dmax+1): # build architecture model = LinearClassifier(linclass_type='lda') # select EFPs with degree <= d X_d = X[:,efpset.sel(('d<=', d))] # do train/val/test split (X_train, X_test, y_train, y_test) = data_split(X_d, y, val=0, test=test_frac) print('Done train/val/test split') # train model model.fit(X_train, y_train) # get predictions on test data preds = model.predict(X_test) # get ROC curve if we have sklearn if roc_curve: rocs.append(roc_curve(y_test, preds[:,1])) # get area under the ROC curve auc = roc_auc_score(y_test, preds[:,1]) print() print('EFPs d <= {} AUC:'.format(d), auc) print() # make ROC curve plot if we have matplotlib if plt: # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # iterate over the ROC curves and plot them for i,d in enumerate(range(1, dmax+1)): plt.plot(rocs[i][1], 1-rocs[i][0], '-', color=colors[i], label='LDA: d <= {} EFPs'.format(d)) # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show() pfn_example.py An example involving Particle Flow Networks (PFNs), cousins of the EFNs , which are to appear. The PFN class is used to construct the network architecture. The output of the example is a plot of the ROC curves obtained by the PFN as well as the jet mass and constituent multiplicity observables. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import PFN from energyflow.datasets import qg_jets from energyflow.utils import data_split, remap_pids, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 100000 val_frac, test_frac = 0.1, 0.15 use_pids = True # network architecture parameters ppm_sizes = (100, 100) dense_sizes = (100, 100) # network training parameters num_epoch = 5 batch_size = 100 ################################################################################ # load data X, y = qg_jets.load(num_data=num_data) # convert labels to categorical Y = to_categorical(y, num_classes=2) print() print('Loaded quark and gluon jets') # preprocess by centering jets and normalizing pts for x in X: mask = x[:,0] > 0 yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0) x[mask,1:3] -= yphi_avg x[mask,0] /= x[:,0].sum() # handle particle id channel if use_pids: remap_pids(X, pid_i=3) else: X = X[:,:,:3] print('Finished preprocessing') # do train/val/test split (X_train, X_val, X_test, Y_train, Y_val, Y_test) = data_split(X, Y, val=val_frac, test=test_frac) print('Done train/val/test split') print('Model summary:') # build architecture pfn = PFN(input_dim=X.shape[-1], ppm_sizes=ppm_sizes, dense_sizes=dense_sizes) # train model pfn.fit(X_train, Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1) # get predictions on test data preds = pfn.predict(X_test, batch_size=1000) # get ROC curve if we have sklearn if roc_curve: pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1]) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('PFN AUC:', auc) print() # make ROC curve plot if we have matplotlib if plt: # get multiplicity and mass for comparison masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphis(x).sum(axis=0)) for x in X]) mults = np.asarray([np.count_nonzero(x[:,0]) for x in X]) mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses) mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults) # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # plot the ROC curves plt.plot(pfn_tp, 1-pfn_fp, '-', color='black', label='PFN') plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass') plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity') # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show()","title":"Examples"},{"location":"examples/#cnn_examplepy","text":"An example involving jet images and convolutional neural networks (CNNs). The CNN class is used to provide a network architecture based on that described in 1612.01551 . Jet images are constructed using the pixelate function and can be either one-channel (grayscale), meaning that only $p_T$ information is used, or two-channel (color), meaning that $p_T$ information and local charged particle counts are used. The images are preprocessed by subtracting the average image in the training set and dividing by the per-pixel standard deviations, using the zero_center and standardize functions, respectively. The output of the example is a plot of the ROC curves of the CNN as well as the jet mass and constituent multiplicity observables. Note that the number of epochs is quite small because it is quite time consuming to train a CNN without a GPU (which will speed up this example immensely). # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import CNN from energyflow.datasets import qg_jets from energyflow.utils import data_split, pixelate, standardize, to_categorical, zero_center # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 100000 val_frac, test_frac = 0.1, 0.15 # image parameters R = 0.4 img_width = 2*R npix = 33 nb_chan = 2 norm = True # required network architecture parameters input_shape = (nb_chan, npix, npix) filter_sizes = [8, 4, 4] num_filters = [8, 8, 8] # very small so can run on non-GPUs in reasonable time # optional network architecture parameters dense_sizes = [50] pool_sizes = 2 # network training parameters num_epoch = 2 batch_size = 100 ################################################################################ # load data X, y = qg_jets.load(num_data=num_data) # convert labels to categorical Y = to_categorical(y, num_classes=2) print('\\n', 'Loaded quark and gluon jets') # make jet images images = np.asarray([pixelate(x, npix=npix, img_width=img_width, nb_chan=nb_chan, charged_counts_only=True, norm=norm) for x in X]) print('Done making jet images') # do train/val/test split (X_train, X_val, X_test, Y_train, Y_val, Y_test) = data_split(images, Y, val=val_frac, test=test_frac) print('Done train/val/test split') # preprocess by zero centering images and standardizing each pixel X_train, X_val, X_test = standardize(*zero_center(X_train, X_val, X_test)) print('Finished preprocessing') print('Model summary:') # build architecture hps = {'input_shape': input_shape, 'filter_sizes': filter_sizes, 'num_filters': num_filters, 'dense_sizes': dense_sizes, 'pool_sizes': pool_sizes} cnn = CNN(hps) # train model cnn.fit(X_train, Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1) # get predictions on test data preds = cnn.predict(X_test, batch_size=1000) # get ROC curve if we have sklearn if roc_curve: cnn_fp, cnn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1]) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('CNN AUC:', auc) print() # make ROC curve plot if we have matplotlib if plt: # get multiplicity and mass for comparison masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphis(x).sum(axis=0)) for x in X]) mults = np.asarray([np.count_nonzero(x[:,0]) for x in X]) mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses) mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults) # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # plot the ROC curves plt.plot(cnn_tp, 1-cnn_fp, '-', color='black', label='CNN') plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass') plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity') # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show()","title":"cnn_example.py"},{"location":"examples/#dnn_examplepy","text":"An example involving deep, fully-connected neural networks (DNNs). The DNN class is used to construct the network architecture. The inputs are taken to be the $N$-subjettiness observables as specified as part of the phase space basis from 1704.08249 , cut off at some total number of observables. The output of the example is a plot showing the ROC curves obtained from training the DNN on different numbers of $N$-subjettiness observables. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import DNN from energyflow.datasets import qg_nsubs from energyflow.utils import data_split, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 100000 val_frac, test_frac = 0.1, 0.15 # network architecture parameters dense_sizes = (100, 100) # network training parameters num_epoch = 10 batch_size = 100 # sweep parameters num_nsubs = [1, 2, 4, 8, 16, 32] colors = ['tab:red', 'tab:orange', 'tab:olive', 'tab:green', 'tab:blue', 'tab:purple'] ################################################################################ # load data X, y = qg_nsubs.load(num_data=num_data) # convert labels to categorical Y = to_categorical(y, num_classes=2) print() print('Loaded quark and gluon jets') print('Model summary:') # train models with different numbers of nsubs as input rocs = [] for i,num_nsub in enumerate(num_nsubs): # build architecture dnn = DNN(input_dim=num_nsub, dense_sizes=dense_sizes, summary=(i==0)) # do train/val/test split (X_train, X_val, X_test, Y_train, Y_val, Y_test) = data_split(X[:,:num_nsub], Y, val=val_frac, test=test_frac) print('Done train/val/test split') # train model dnn.fit(X_train, Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1) # get predictions on test data preds = dnn.predict(X_test, batch_size=1000) # get ROC curve if we have sklearn if roc_curve: rocs.append(roc_curve(Y_test[:,1], preds[:,1])) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('{} nsubs DNN AUC:'.format(num_nsub), auc) print() # make ROC curve plot if we have matplotlib if plt: # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # iterate over the ROC curves and plot them for i in range(len(rocs)): plt.plot(rocs[i][1], 1-rocs[i][0], '-', color=colors[i], label='DNN: {} N-subs'.format(num_nsubs[i])) # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show()","title":"dnn_example.py"},{"location":"examples/#efn_examplepy","text":"An example involving Energy Flow Networks (EFNs), which are to appear soon in a paper by P. T. Komiske, E. M. Metodiev, and J. Thaler. See this talk for a brief overview of the EFN architecture. The EFN class is used to construct the network architecture. The output of the example is a plot of the ROC curves obtained by the EFN as well as the jet mass and constituent multiplicity observables. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import EFN from energyflow.datasets import qg_jets from energyflow.utils import data_split, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 100000 val_frac, test_frac = 0.1, 0.15 # network architecture parameters ppm_sizes = (100, 100) dense_sizes = (100, 100) # network training parameters num_epoch = 5 batch_size = 100 ################################################################################ # load data X, y = qg_jets.load(num_data=num_data) # ignore pid information X = X[:,:,:3] # convert labels to categorical Y = to_categorical(y, num_classes=2) print() print('Loaded quark and gluon jets') # preprocess by centering jets and normalizing pts for x in X: mask = x[:,0] > 0 yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0) x[mask,1:3] -= yphi_avg x[mask,0] /= x[:,0].sum() print('Finished preprocessing') # do train/val/test split (z_train, z_val, z_test, p_train, p_val, p_test, Y_train, Y_val, Y_test) = data_split(X[:,:,0], X[:,:,1:], Y, val=val_frac, test=test_frac) print('Done train/val/test split') print('Model summary:') # build architecture efn = EFN(input_dim=2, ppm_sizes=ppm_sizes, dense_sizes=dense_sizes) # train model efn.fit([z_train, p_train], Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=([z_val, p_val], Y_val), verbose=1) # get predictions on test data preds = efn.predict([z_test, p_test], batch_size=1000) # get ROC curve if we have sklearn if roc_curve: efn_fp, efn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1]) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('EFN AUC:', auc) print() # make ROC curve plot if we have matplotlib if plt: # get multiplicity and mass for comparison masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphis(x).sum(axis=0)) for x in X]) mults = np.asarray([np.count_nonzero(x[:,0]) for x in X]) mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses) mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults) # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # plot the ROC curves plt.plot(efn_tp, 1-efn_fp, '-', color='black', label='EFN') plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass') plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity') # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show()","title":"efn_example.py"},{"location":"examples/#efp_examplepy","text":"An example involving Energy Flow Polynomials (EFPs) and a linear classifier (Fisher's Linear Discriminant by default). First, the EFPSet class is used to compute the EFPs up to the specified dmax , the default being dmax=5 . Then linear classifiers are trained for different numbers of EFPs as input, determined by taking all EFPs up to degree d with d from 1 to dmax . The output of the example is a plot of the ROC curves for the classifiers with different numbers of EFP inputs. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import LinearClassifier from energyflow.datasets import qg_jets from energyflow.utils import data_split, standardize, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 20000 test_frac = 0.2 # efp parameters dmax = 5 measure = 'hadr' beta = 0.5 # plotting colors = ['tab:red', 'tab:orange', 'tab:olive', 'tab:green', 'tab:blue'] ################################################################################ # load data X, y = qg_jets.load(num_data) print() print('Loaded quark and gluon jets') # calculate EFPs print('Calculating d <= {} EFPs for {} jets... '.format(dmax, num_data), end='') efpset = ef.EFPSet(('d<=', dmax), measure='hadr', beta=beta) masked_X = [x[x[:,0] > 0] for x in X] X = efpset.batch_compute(masked_X) print('Done') # train models with different numbers of EFPs as input rocs = [] for d in range(1, dmax+1): # build architecture model = LinearClassifier(linclass_type='lda') # select EFPs with degree <= d X_d = X[:,efpset.sel(('d<=', d))] # do train/val/test split (X_train, X_test, y_train, y_test) = data_split(X_d, y, val=0, test=test_frac) print('Done train/val/test split') # train model model.fit(X_train, y_train) # get predictions on test data preds = model.predict(X_test) # get ROC curve if we have sklearn if roc_curve: rocs.append(roc_curve(y_test, preds[:,1])) # get area under the ROC curve auc = roc_auc_score(y_test, preds[:,1]) print() print('EFPs d <= {} AUC:'.format(d), auc) print() # make ROC curve plot if we have matplotlib if plt: # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # iterate over the ROC curves and plot them for i,d in enumerate(range(1, dmax+1)): plt.plot(rocs[i][1], 1-rocs[i][0], '-', color=colors[i], label='LDA: d <= {} EFPs'.format(d)) # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show()","title":"efp_example.py"},{"location":"examples/#pfn_examplepy","text":"An example involving Particle Flow Networks (PFNs), cousins of the EFNs , which are to appear. The PFN class is used to construct the network architecture. The output of the example is a plot of the ROC curves obtained by the PFN as well as the jet mass and constituent multiplicity observables. # standard library imports from __future__ import absolute_import, division, print_function # standard numerical library imports import numpy as np # energyflow imports import energyflow as ef from energyflow.archs import PFN from energyflow.datasets import qg_jets from energyflow.utils import data_split, remap_pids, to_categorical # attempt to import sklearn try: from sklearn.metrics import roc_auc_score, roc_curve except: print('please install scikit-learn in order to make ROC curves') roc_curve = False # attempt to import matplotlib try: import matplotlib.pyplot as plt except: print('please install matploltib in order to make plots') plt = False ################################### SETTINGS ################################### # data controls num_data = 100000 val_frac, test_frac = 0.1, 0.15 use_pids = True # network architecture parameters ppm_sizes = (100, 100) dense_sizes = (100, 100) # network training parameters num_epoch = 5 batch_size = 100 ################################################################################ # load data X, y = qg_jets.load(num_data=num_data) # convert labels to categorical Y = to_categorical(y, num_classes=2) print() print('Loaded quark and gluon jets') # preprocess by centering jets and normalizing pts for x in X: mask = x[:,0] > 0 yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0) x[mask,1:3] -= yphi_avg x[mask,0] /= x[:,0].sum() # handle particle id channel if use_pids: remap_pids(X, pid_i=3) else: X = X[:,:,:3] print('Finished preprocessing') # do train/val/test split (X_train, X_val, X_test, Y_train, Y_val, Y_test) = data_split(X, Y, val=val_frac, test=test_frac) print('Done train/val/test split') print('Model summary:') # build architecture pfn = PFN(input_dim=X.shape[-1], ppm_sizes=ppm_sizes, dense_sizes=dense_sizes) # train model pfn.fit(X_train, Y_train, epochs=num_epoch, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1) # get predictions on test data preds = pfn.predict(X_test, batch_size=1000) # get ROC curve if we have sklearn if roc_curve: pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1]) # get area under the ROC curve auc = roc_auc_score(Y_test[:,1], preds[:,1]) print() print('PFN AUC:', auc) print() # make ROC curve plot if we have matplotlib if plt: # get multiplicity and mass for comparison masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphis(x).sum(axis=0)) for x in X]) mults = np.asarray([np.count_nonzero(x[:,0]) for x in X]) mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses) mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults) # some nicer plot settings plt.rcParams['figure.figsize'] = (4,4) plt.rcParams['font.family'] = 'serif' plt.rcParams['figure.autolayout'] = True # plot the ROC curves plt.plot(pfn_tp, 1-pfn_fp, '-', color='black', label='PFN') plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass') plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity') # axes labels plt.xlabel('Quark Jet Efficiency') plt.ylabel('Gluon Jet Rejection') # axes limits plt.xlim(0, 1) plt.ylim(0, 1) # make legend and show plot plt.legend(loc='lower left', frameon=False) plt.show()","title":"pfn_example.py"},{"location":"faq/","text":"Frequently Asked EnergyFlow Questions How do I cite the EnergyFlow package? Why Python instead of C++? Can I contribute to the code? How do I report an issue or a bug? Where can I get graph image files? How do I cite the EnergyFlow package? Please cite the relevant Energy Flow papers if they or this package helps your research. Here are the BibTeX entries to use: @article{Komiske:2017aww, author = \"Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse\", title = \"{Energy Flow Polynomials: A complete linear basis for jet substructure}\", journal = \"JHEP\", volume = \"04\", year = \"2018\", pages = \"013\", doi = \"10.1007/JHEP04(2018)013\", eprint = \"1712.07124\", archivePrefix = \"arXiv\", primaryClass = \"hep-ph\", reportNumber = \"MIT-CTP-4965\" } Why Python instead of C++? Computing the energy flow polynomials requires a function such as NumPy's einsum that can efficiently evaluate arbitrary tensor contractions. To write such a function from scratch in C++ is difficult, and there is no obvious library in C++ to use (though if one were to attempt this the tensor algebra compiler seems like a promising tool). NumPy is a highly-optimized Python library written in C that provides all of the tools required to efficiently compute the energy flow polynomials. Libraries like NumPy take advantage of optimizations that the physicist-programmer typically does not, such as architecture-optimized libraries like BLAS or LAPACK and low-level features such as SSE instructions. Can I contribute to the code? All of our code is open source and hosted on GitHub . We welcome additional contributors, and if you are interested in getting involved please contact us directly. Contact information is included in the relevant Energy Flow papers and our GitHub repository. How do I report an issue? Please let us know of any issues you encounter as soon as possible by creating an Issue on the EnergyFlow GitHub repository. Where can I get graph image files? Image files for all connected multigraphs with up to 7 edges in the energy flow polynomial style are available as pdf files here . You are free to use them with the proper attribution.","title":"FAQ"},{"location":"faq/#frequently-asked-energyflow-questions","text":"How do I cite the EnergyFlow package? Why Python instead of C++? Can I contribute to the code? How do I report an issue or a bug? Where can I get graph image files?","title":"Frequently Asked EnergyFlow Questions"},{"location":"faq/#how-do-i-cite-the-energyflow-package","text":"Please cite the relevant Energy Flow papers if they or this package helps your research. Here are the BibTeX entries to use: @article{Komiske:2017aww, author = \"Komiske, Patrick T. and Metodiev, Eric M. and Thaler, Jesse\", title = \"{Energy Flow Polynomials: A complete linear basis for jet substructure}\", journal = \"JHEP\", volume = \"04\", year = \"2018\", pages = \"013\", doi = \"10.1007/JHEP04(2018)013\", eprint = \"1712.07124\", archivePrefix = \"arXiv\", primaryClass = \"hep-ph\", reportNumber = \"MIT-CTP-4965\" }","title":"How do I cite the EnergyFlow package?"},{"location":"faq/#why-python-instead-of-c","text":"Computing the energy flow polynomials requires a function such as NumPy's einsum that can efficiently evaluate arbitrary tensor contractions. To write such a function from scratch in C++ is difficult, and there is no obvious library in C++ to use (though if one were to attempt this the tensor algebra compiler seems like a promising tool). NumPy is a highly-optimized Python library written in C that provides all of the tools required to efficiently compute the energy flow polynomials. Libraries like NumPy take advantage of optimizations that the physicist-programmer typically does not, such as architecture-optimized libraries like BLAS or LAPACK and low-level features such as SSE instructions.","title":"Why Python instead of C++?"},{"location":"faq/#can-i-contribute-to-the-code","text":"All of our code is open source and hosted on GitHub . We welcome additional contributors, and if you are interested in getting involved please contact us directly. Contact information is included in the relevant Energy Flow papers and our GitHub repository.","title":"Can I contribute to the code?"},{"location":"faq/#how-do-i-report-an-issue","text":"Please let us know of any issues you encounter as soon as possible by creating an Issue on the EnergyFlow GitHub repository.","title":"How do I report an issue?"},{"location":"faq/#where-can-i-get-graph-image-files","text":"Image files for all connected multigraphs with up to 7 edges in the energy flow polynomial style are available as pdf files here . You are free to use them with the proper attribution.","title":"Where can I get graph image files?"},{"location":"installation/","text":"The EnergyFlow package is written in pure Python and depends only on NumPy, the fundamental package for scientific computing with Python, and six, which is a lightweight module to patch some inconvenient differences between Python 2 and Python 3. The EnergyFlow package is designed to work with Python 2.7, 3.5, 3.6, and 3.7. These can be installed from here . The latest stable version of Python 3 is highly recommended. Install with pip (recommended) To install from PyPI using pip , make sure you have one of the supported versions of Python installed and that pip is available in the system path. Simply execute pip install energyflow and EnergyFlow will be installed in your default location for Python packages. Bleeding edge install EnergyFlow is hosted on GitHub and can be installed by cloning the repository and running python setup.py install . This is not generally recommend as the master branch may contain unstable features. iGraph EnergyFlow relies on iGraph for generation of multigraphs. This is not required if using the provided graphs suits your needs. If you wish to generate your own graphs, make sure that iGraph is importable. NumPy Since EnergyFlow relies on numpy.einsum to do most of the computational heavy lifting, newer versions of NumPy may provide changes/speedups in performance if einsum changes. NumPy 1.14.0 changed einsum to use tensordot when possible compared to 1.13.3 , which only used c_einsum . This means that computations are faster on larger tensors but may be slower on smaller tensors. EnergyFlow currently uses only c_einsum because it was found to be substantially faster for typical pp-jet applications.","title":"Installation"},{"location":"installation/#install-with-pip-recommended","text":"To install from PyPI using pip , make sure you have one of the supported versions of Python installed and that pip is available in the system path. Simply execute pip install energyflow and EnergyFlow will be installed in your default location for Python packages.","title":"Install with pip (recommended)"},{"location":"installation/#bleeding-edge-install","text":"EnergyFlow is hosted on GitHub and can be installed by cloning the repository and running python setup.py install . This is not generally recommend as the master branch may contain unstable features.","title":"Bleeding edge install"},{"location":"installation/#igraph","text":"EnergyFlow relies on iGraph for generation of multigraphs. This is not required if using the provided graphs suits your needs. If you wish to generate your own graphs, make sure that iGraph is importable.","title":"iGraph"},{"location":"installation/#numpy","text":"Since EnergyFlow relies on numpy.einsum to do most of the computational heavy lifting, newer versions of NumPy may provide changes/speedups in performance if einsum changes. NumPy 1.14.0 changed einsum to use tensordot when possible compared to 1.13.3 , which only used c_einsum . This means that computations are faster on larger tensors but may be slower on smaller tensors. EnergyFlow currently uses only c_einsum because it was found to be substantially faster for typical pp-jet applications.","title":"NumPy"},{"location":"tutorial/","text":"Jupyter Notebook Demo For an introduction to EnergyFlow, you can view or download a demo notebook here .","title":"Tutorial"},{"location":"tutorial/#jupyter-notebook-demo","text":"For an introduction to EnergyFlow, you can view or download a demo notebook here .","title":"Jupyter Notebook Demo"},{"location":"docs/archs/","text":"EnergyFlow contains a few model architectures for ease of using common models that frequently appear in the intersection of the particle physics and ML worlds. Since these architectures are not used by the core EnergyFlow code, and require the external Keras and scikit-learn libraries, they are not imported by default but must be explicitly imported, e.g. from energyflow.archs import * . ArchBase Base class for all architectures contained in EnergyFlow. The mechanism of specifying hyperparameters for all architectures is described here. Methods common to all architectures are documented here. Note that this class cannot be instantiated directly as it is an abstract base class. energyflow.archs.archbase.ArchBase(*args, **kwargs) Accepts arbitrary arguments. Positional arguments (if present) are dictionaries of hyperparameters, keyword arguments (if present) are hyperparameters directly. Keyword hyperparameters take precedence over positional hyperparameter dictionaries. Arguments *args : arbitrary positional arguments Each argument is a dictionary containing hyperparameter (name, value) pairs. *kwargs : arbitrary keyword arguments Hyperparameters as keyword arguments. Takes precedence over the positional arguments. fit fit(X_train, Y_train, **kwargs) Train the model by fitting the provided training dataset and labels. Transparently calls the fit() method of the underlying model. Arguments X_train : numpy.ndarray The training dataset as an array of features for each sample. Y_train : numpy.ndarray The labels for the training dataset. May need to be one-hot encoded depending on the requirements of the underlying model (typically Keras models will use one-hot encoding whereas the linear model does not.) kwargs : dict Keyword arguments passed on to the Keras method of the same name. See the Keras model docs for details on available parameters. Returns Whatever the underlying model's fit() returns. predict predict(X_test, **kwargs) Evaluate the model on a dataset. Arguments X_test : numpy.ndarray The dataset to evaluate the model on. kwargs : dict Keyword arguments passed on to the Keras method of the same name. See the Keras model docs for details on available parameters. Returns numpy.ndarray The value of the model on the input dataset. model model The underlying model held by this architecture. CNN Convolutional Neural Network architecture. energyflow.archs.CNN(*args, **kwargs) See ArchBase for how to pass in hyperparameters. Required CNN Hyperparameters input_shape : { tuple , list } of int The shape of a single jet image. Assuming that data_format is set to channels_first , this is (nb_chan,npix,npix) . filter_sizes : { tuple , list } of int The size of the filters, which are taken to be square, in each convolutional layer of the network. The length of the list will be the number of convolutional layers in the network. num_filters : { tuple , list } of int The number of filters in each convolutional layer. The length of num_filters must match that of filter_sizes . Default CNN Hyperparameters dense_sizes = None : { tuple , list } of int The sizes of the dense layer backend. A value of None is equivalent to an empty list. pool_sizes = None : { tuple , list } of int Size of maxpooling filter, taken to be a square. A value of None will not use maxpooling. conv_acts = 'relu' : { tuple , list } of str Activation function(s) for the conv layers. A single string will apply the same activation to all conv layers. See the Keras activations docs for more detail. dense_acts = 'relu' : { tuple , list } of str Activation functions(s) for the dense layers. A single string will apply the same activation to all dense layers. conv_k_inits = 'he_uniform' : { tuple , list } of str Kernel initializers for the convolutional layers. A single string will apply the same initializer to all layers. See the Keras initializer docs for more detail. dense_k_inits = 'he_uniform' : { tuple , list } of str Kernel initializers for the dense layers. A single string will apply the same initializer to all layers. conv_dropouts = 0 : { tuple , list } of float Dropout rates for the convolutional layers. A single float will apply the same dropout rate to all conv layers. See the Keras Dropout layer for more detail. num_spatial2d_dropout = 0 : int The number of convolutional layers, starting from the beginning of the model, for which to apply SpatialDropout2D instead of Dropout. dense_dropouts = 0 : { tuple , list } of float Dropout rates for the dense layers. A single float will apply the same dropout rate to all dense layers. paddings = 'valid' : { tuple , list } of str Controls how the filters are convoled with the inputs. See the Keras Conv2D layer for more detail. data_format = 'channels_first' : { 'channels_first' , 'channels_last' } Sets which axis is expected to contain the different channels. Default NN Hyperparameters loss = 'categorical_crossentropy' : str The loss function to use for the model. See the Keras loss function docs for available loss functions. lr = 0.001 : float The learning rate for the model. opt = Adam : Keras optimizer A Keras optimizer . output_dim = 2 : int The output dimension of the model. output_act = 'softmax' : str Activation function to apply to the output. metrics = ['accuracy'] : list of str The Keras metrics to apply to the model. compile = True : bool Whether the model should be compiled or not. summary = True : bool Whether a summary should be printed or not. DNN Dense Neural Network architecture. energyflow.archs.DNN(*args, **kwargs) See ArchBase for how to pass in hyperparameters. Required DNN Hyperparameters input_dim : int The number of inputs to the model. dense_sizes : { tuple , list } of int The number of nodes in the dense layers of the model. Default DNN Hyperparameters acts = 'relu' : { tuple , list } of str Activation functions(s) for the dense layers. A single string will apply the same activation to all layers. See the Keras activations docs for more detail. k_inits = 'he_uniform' : { tuple , list } of str Kernel initializers for the dense layers. A single string will apply the same initializer to all layers. See the Keras initializer docs for more detail. dropouts = 0 : { tuple , list } of float Dropout rates for the dense layers. A single float will apply the same dropout rate to all layers. See the Keras Dropout layer for more detail. l2_regs = 0 : { tuple , list } of float $L_2$-regulatization strength for both the weights and biases of the dense layers. A single float will apply the same $L_2$-regulatization to all layers. Default NN Hyperparameters loss = 'categorical_crossentropy' : str The loss function to use for the model. See the Keras loss function docs for available loss functions. lr = 0.001 : float The learning rate for the model. opt = Adam : Keras optimizer A Keras optimizer . output_dim = 2 : int The output dimension of the model. output_act = 'softmax' : str Activation function to apply to the output. metrics = ['accuracy'] : list of str The Keras metrics to apply to the model. compile = True : bool Whether the model should be compiled or not. summary = True : bool Whether a summary should be printed or not. EFN Energy Flow Neural Network architecture. energyflow.archs.EFN(*args, **kwargs) See ArchBase for how to pass in hyperparameters. Required EFN Hyperparameters input_dim : int The number of features for each particle. ppm_sizes : { tuple , list } of int The sizes of the dense layers in the per-particle frontend module. The last element will be the number of latent observables that the model defines. dense_sizes : { tuple , list } of int The sizes of the dense layers in the backend module. Default EFN Hyperparameters ppm_acts = 'relu' : { tuple , list } of str Activation functions(s) for the dense layers in the per-particle frontend module. A single string will apply the same activation to all layers. See the Keras activations docs for more detail. dense_acts = 'relu' : { tuple , list } of str Activation functions(s) for the dense layers in the backend module. A single string will apply the same activation to all layers. ppm_k_inits = 'he_uniform' : { tuple , list } of str Kernel initializers for the dense layers in the per-particle frontend module. A single string will apply the same initializer to all layers. See the Keras initializer docs for more detail. dense_k_inits = 'he_uniform' : { tuple , list } of str Kernel initializers for the dense layers in the backend module. A single string will apply the same initializer to all layers. latent_dropout = 0 : float Dropout rates for the summation layer that defines the value of the latent observables on the inputs. See the Keras Dropout layer for more detail. dense_dropouts = 0 : { tuple , list } of float Dropout rates for the dense layers in the backend module. A single float will apply the same dropout rate to all dense layers. mask_val = 0 : float The value for which particles with all features set equal to this value will be ignored. See the Keras Masking layer for more detail. Default NN Hyperparameters loss = 'categorical_crossentropy' : str The loss function to use for the model. See the Keras loss function docs for available loss functions. lr = 0.001 : float The learning rate for the model. opt = Adam : Keras optimizer A Keras optimizer . output_dim = 2 : int The output dimension of the model. output_act = 'softmax' : str Activation function to apply to the output. metrics = ['accuracy'] : list of str The Keras metrics to apply to the model. compile = True : bool Whether the model should be compiled or not. summary = True : bool Whether a summary should be printed or not. PFN Particle Flow Neural Network architecture. Accepts the same hperparameters as the EFN . energyflow.archs.PFN(*args, **kwargs) LinearClassifier Linear classifier that can be either Fisher's linear discriminant or logistic regression. Relies on the scikit-learn implementations of these classifiers. energyflow.archs.LinearClassifier(*args, **kwargs) See ArchBase for how to pass in hyperparameters. Default Hyperparameters linclass_type = 'lda' : { 'lda' , 'lr' } Controls which type of linear classifier is used. 'lda' corresponds to LinearDisciminantAnalysis and 'lr' to Logistic Regression . If using 'lr' all arguments are passed on directly to the scikit-learn class. LDA Hyperparameters solver = 'svd' : { 'svd' , 'lsqr' , 'eigen' } Which LDA solver to use. tol = 1e-10 : float Threshold used for rank estimation. Notably not a convergence parameter.","title":"Architectures"},{"location":"docs/archs/#archbase","text":"Base class for all architectures contained in EnergyFlow. The mechanism of specifying hyperparameters for all architectures is described here. Methods common to all architectures are documented here. Note that this class cannot be instantiated directly as it is an abstract base class. energyflow.archs.archbase.ArchBase(*args, **kwargs) Accepts arbitrary arguments. Positional arguments (if present) are dictionaries of hyperparameters, keyword arguments (if present) are hyperparameters directly. Keyword hyperparameters take precedence over positional hyperparameter dictionaries. Arguments *args : arbitrary positional arguments Each argument is a dictionary containing hyperparameter (name, value) pairs. *kwargs : arbitrary keyword arguments Hyperparameters as keyword arguments. Takes precedence over the positional arguments.","title":"ArchBase"},{"location":"docs/archs/#fit","text":"fit(X_train, Y_train, **kwargs) Train the model by fitting the provided training dataset and labels. Transparently calls the fit() method of the underlying model. Arguments X_train : numpy.ndarray The training dataset as an array of features for each sample. Y_train : numpy.ndarray The labels for the training dataset. May need to be one-hot encoded depending on the requirements of the underlying model (typically Keras models will use one-hot encoding whereas the linear model does not.) kwargs : dict Keyword arguments passed on to the Keras method of the same name. See the Keras model docs for details on available parameters. Returns Whatever the underlying model's fit() returns.","title":"fit"},{"location":"docs/archs/#predict","text":"predict(X_test, **kwargs) Evaluate the model on a dataset. Arguments X_test : numpy.ndarray The dataset to evaluate the model on. kwargs : dict Keyword arguments passed on to the Keras method of the same name. See the Keras model docs for details on available parameters. Returns numpy.ndarray The value of the model on the input dataset.","title":"predict"},{"location":"docs/archs/#model","text":"model The underlying model held by this architecture.","title":"model"},{"location":"docs/archs/#cnn","text":"Convolutional Neural Network architecture. energyflow.archs.CNN(*args, **kwargs) See ArchBase for how to pass in hyperparameters. Required CNN Hyperparameters input_shape : { tuple , list } of int The shape of a single jet image. Assuming that data_format is set to channels_first , this is (nb_chan,npix,npix) . filter_sizes : { tuple , list } of int The size of the filters, which are taken to be square, in each convolutional layer of the network. The length of the list will be the number of convolutional layers in the network. num_filters : { tuple , list } of int The number of filters in each convolutional layer. The length of num_filters must match that of filter_sizes . Default CNN Hyperparameters dense_sizes = None : { tuple , list } of int The sizes of the dense layer backend. A value of None is equivalent to an empty list. pool_sizes = None : { tuple , list } of int Size of maxpooling filter, taken to be a square. A value of None will not use maxpooling. conv_acts = 'relu' : { tuple , list } of str Activation function(s) for the conv layers. A single string will apply the same activation to all conv layers. See the Keras activations docs for more detail. dense_acts = 'relu' : { tuple , list } of str Activation functions(s) for the dense layers. A single string will apply the same activation to all dense layers. conv_k_inits = 'he_uniform' : { tuple , list } of str Kernel initializers for the convolutional layers. A single string will apply the same initializer to all layers. See the Keras initializer docs for more detail. dense_k_inits = 'he_uniform' : { tuple , list } of str Kernel initializers for the dense layers. A single string will apply the same initializer to all layers. conv_dropouts = 0 : { tuple , list } of float Dropout rates for the convolutional layers. A single float will apply the same dropout rate to all conv layers. See the Keras Dropout layer for more detail. num_spatial2d_dropout = 0 : int The number of convolutional layers, starting from the beginning of the model, for which to apply SpatialDropout2D instead of Dropout. dense_dropouts = 0 : { tuple , list } of float Dropout rates for the dense layers. A single float will apply the same dropout rate to all dense layers. paddings = 'valid' : { tuple , list } of str Controls how the filters are convoled with the inputs. See the Keras Conv2D layer for more detail. data_format = 'channels_first' : { 'channels_first' , 'channels_last' } Sets which axis is expected to contain the different channels. Default NN Hyperparameters loss = 'categorical_crossentropy' : str The loss function to use for the model. See the Keras loss function docs for available loss functions. lr = 0.001 : float The learning rate for the model. opt = Adam : Keras optimizer A Keras optimizer . output_dim = 2 : int The output dimension of the model. output_act = 'softmax' : str Activation function to apply to the output. metrics = ['accuracy'] : list of str The Keras metrics to apply to the model. compile = True : bool Whether the model should be compiled or not. summary = True : bool Whether a summary should be printed or not.","title":"CNN"},{"location":"docs/archs/#dnn","text":"Dense Neural Network architecture. energyflow.archs.DNN(*args, **kwargs) See ArchBase for how to pass in hyperparameters. Required DNN Hyperparameters input_dim : int The number of inputs to the model. dense_sizes : { tuple , list } of int The number of nodes in the dense layers of the model. Default DNN Hyperparameters acts = 'relu' : { tuple , list } of str Activation functions(s) for the dense layers. A single string will apply the same activation to all layers. See the Keras activations docs for more detail. k_inits = 'he_uniform' : { tuple , list } of str Kernel initializers for the dense layers. A single string will apply the same initializer to all layers. See the Keras initializer docs for more detail. dropouts = 0 : { tuple , list } of float Dropout rates for the dense layers. A single float will apply the same dropout rate to all layers. See the Keras Dropout layer for more detail. l2_regs = 0 : { tuple , list } of float $L_2$-regulatization strength for both the weights and biases of the dense layers. A single float will apply the same $L_2$-regulatization to all layers. Default NN Hyperparameters loss = 'categorical_crossentropy' : str The loss function to use for the model. See the Keras loss function docs for available loss functions. lr = 0.001 : float The learning rate for the model. opt = Adam : Keras optimizer A Keras optimizer . output_dim = 2 : int The output dimension of the model. output_act = 'softmax' : str Activation function to apply to the output. metrics = ['accuracy'] : list of str The Keras metrics to apply to the model. compile = True : bool Whether the model should be compiled or not. summary = True : bool Whether a summary should be printed or not.","title":"DNN"},{"location":"docs/archs/#efn","text":"Energy Flow Neural Network architecture. energyflow.archs.EFN(*args, **kwargs) See ArchBase for how to pass in hyperparameters. Required EFN Hyperparameters input_dim : int The number of features for each particle. ppm_sizes : { tuple , list } of int The sizes of the dense layers in the per-particle frontend module. The last element will be the number of latent observables that the model defines. dense_sizes : { tuple , list } of int The sizes of the dense layers in the backend module. Default EFN Hyperparameters ppm_acts = 'relu' : { tuple , list } of str Activation functions(s) for the dense layers in the per-particle frontend module. A single string will apply the same activation to all layers. See the Keras activations docs for more detail. dense_acts = 'relu' : { tuple , list } of str Activation functions(s) for the dense layers in the backend module. A single string will apply the same activation to all layers. ppm_k_inits = 'he_uniform' : { tuple , list } of str Kernel initializers for the dense layers in the per-particle frontend module. A single string will apply the same initializer to all layers. See the Keras initializer docs for more detail. dense_k_inits = 'he_uniform' : { tuple , list } of str Kernel initializers for the dense layers in the backend module. A single string will apply the same initializer to all layers. latent_dropout = 0 : float Dropout rates for the summation layer that defines the value of the latent observables on the inputs. See the Keras Dropout layer for more detail. dense_dropouts = 0 : { tuple , list } of float Dropout rates for the dense layers in the backend module. A single float will apply the same dropout rate to all dense layers. mask_val = 0 : float The value for which particles with all features set equal to this value will be ignored. See the Keras Masking layer for more detail. Default NN Hyperparameters loss = 'categorical_crossentropy' : str The loss function to use for the model. See the Keras loss function docs for available loss functions. lr = 0.001 : float The learning rate for the model. opt = Adam : Keras optimizer A Keras optimizer . output_dim = 2 : int The output dimension of the model. output_act = 'softmax' : str Activation function to apply to the output. metrics = ['accuracy'] : list of str The Keras metrics to apply to the model. compile = True : bool Whether the model should be compiled or not. summary = True : bool Whether a summary should be printed or not.","title":"EFN"},{"location":"docs/archs/#pfn","text":"Particle Flow Neural Network architecture. Accepts the same hperparameters as the EFN . energyflow.archs.PFN(*args, **kwargs)","title":"PFN"},{"location":"docs/archs/#linearclassifier","text":"Linear classifier that can be either Fisher's linear discriminant or logistic regression. Relies on the scikit-learn implementations of these classifiers. energyflow.archs.LinearClassifier(*args, **kwargs) See ArchBase for how to pass in hyperparameters. Default Hyperparameters linclass_type = 'lda' : { 'lda' , 'lr' } Controls which type of linear classifier is used. 'lda' corresponds to LinearDisciminantAnalysis and 'lr' to Logistic Regression . If using 'lr' all arguments are passed on directly to the scikit-learn class. LDA Hyperparameters solver = 'svd' : { 'svd' , 'lsqr' , 'eigen' } Which LDA solver to use. tol = 1e-10 : float Threshold used for rank estimation. Notably not a convergence parameter.","title":"LinearClassifier"},{"location":"docs/datasets/","text":"QG_jets A dataset consisting of 100k quark and gluon jets generated with Pythia 8.230. The dataset contains two members: 'X' which is a numpy array of the jets that has shape (100000,139,4) and 'y' which is a numpy array of quark/gluon labels (quark= 1 and gluon= 0 ). The jets are padded with zero-particles in order to make a contiguous array. The particles are given as (pt,y,phi,pid) values where pid is the particle's PDG id . load energyflow.datasets.load(num_data=-1, filename='QG_jets.npz', cache_dir=None) Loads the dataset. The first time this is called, it will automatically download the dataset. Future calls will attempt to use the cached dataset prior to redownloading. Arguments num_data : int The number of events to return. A value of -1 means read in all events. filename : str The filename where to store/look for the file. cache_dir : str The directory where to store/look for the file. Returns 3-d numpy.ndarray , 1-d numpy.ndarray The X and y components of the dataset as specified above. QG_nsubs A dataset consisting of 45 $N$-subjettiness observables for 100k quark and gluon jets generated with Pythia 8.230. Following 1704.08249 , the observables are in the following order: \\{\\tau_1^{(\\beta=0.5)},\\tau_1^{(\\beta=1.0)},\\tau_1^{(\\beta=2.0)}, \\tau_2^{(\\beta=0.5)},\\tau_2^{(\\beta=1.0)},\\tau_2^{(\\beta=2.0)}, \\ldots, \\tau_{15}^{(\\beta=0.5)},\\tau_{15}^{(\\beta=1.0)},\\tau_{15}^{(\\beta=2.0)}\\}. The dataset contains two members: 'X' which is a numpy array of the nsubs that has shape (100000,45) and 'y' which is a numpy array of quark/gluon labels (quark= 1 and gluon= 0 ). load energyflow.datasets.load(num_data=-1, filename='QG_nsubs.npz', cache_dir=None) Loads the dataset. The first time this is called, it will automatically download the dataset. Future calls will attempt to use the cached dataset prior to redownloading. Arguments num_data : int The number of events to return. A value of -1 means read in all events. filename : str The filename where to store/look for the file. cache_dir : str The directory where to store/look for the file. Returns 3-d numpy.ndarray , 1-d numpy.ndarray The X and y components of the dataset as specified above.","title":"Datasets"},{"location":"docs/datasets/#qg_jets","text":"A dataset consisting of 100k quark and gluon jets generated with Pythia 8.230. The dataset contains two members: 'X' which is a numpy array of the jets that has shape (100000,139,4) and 'y' which is a numpy array of quark/gluon labels (quark= 1 and gluon= 0 ). The jets are padded with zero-particles in order to make a contiguous array. The particles are given as (pt,y,phi,pid) values where pid is the particle's PDG id .","title":"QG_jets"},{"location":"docs/datasets/#load","text":"energyflow.datasets.load(num_data=-1, filename='QG_jets.npz', cache_dir=None) Loads the dataset. The first time this is called, it will automatically download the dataset. Future calls will attempt to use the cached dataset prior to redownloading. Arguments num_data : int The number of events to return. A value of -1 means read in all events. filename : str The filename where to store/look for the file. cache_dir : str The directory where to store/look for the file. Returns 3-d numpy.ndarray , 1-d numpy.ndarray The X and y components of the dataset as specified above.","title":"load"},{"location":"docs/datasets/#qg_nsubs","text":"A dataset consisting of 45 $N$-subjettiness observables for 100k quark and gluon jets generated with Pythia 8.230. Following 1704.08249 , the observables are in the following order: \\{\\tau_1^{(\\beta=0.5)},\\tau_1^{(\\beta=1.0)},\\tau_1^{(\\beta=2.0)}, \\tau_2^{(\\beta=0.5)},\\tau_2^{(\\beta=1.0)},\\tau_2^{(\\beta=2.0)}, \\ldots, \\tau_{15}^{(\\beta=0.5)},\\tau_{15}^{(\\beta=1.0)},\\tau_{15}^{(\\beta=2.0)}\\}. The dataset contains two members: 'X' which is a numpy array of the nsubs that has shape (100000,45) and 'y' which is a numpy array of quark/gluon labels (quark= 1 and gluon= 0 ).","title":"QG_nsubs"},{"location":"docs/datasets/#load_1","text":"energyflow.datasets.load(num_data=-1, filename='QG_nsubs.npz', cache_dir=None) Loads the dataset. The first time this is called, it will automatically download the dataset. Future calls will attempt to use the cached dataset prior to redownloading. Arguments num_data : int The number of events to return. A value of -1 means read in all events. filename : str The filename where to store/look for the file. cache_dir : str The directory where to store/look for the file. Returns 3-d numpy.ndarray , 1-d numpy.ndarray The X and y components of the dataset as specified above.","title":"load"},{"location":"docs/efp/","text":"Energy Flow Polynomials (EFPs) are a set of observables, indexed by non-isomorphic multigraphs, which linearly span the space of infrared and collinear safe (IRC-safe) observables. An EFP index by a multigraph $G$ takes the following form: \\text{EFP}_G=\\sum_{i_1=1}^M\\cdots\\sum_{i_N=1}^Mz_{i_1}\\cdots z_{i_N} \\prod_{(k,\\ell)\\in G}\\theta_{i_ki_\\ell} where $z_i$ is a measure of the energy of particle $i$ and $\\theta_{ij}$ is a measure of the angular separation between particles $i$ and $j$. The specific choices for energy and angular measure depend on the collider context and are discussed at length in the Measures section. EFP A class for representing and computing a single EFP. Note that all keyword arguments are stored as properties of the EFP instance. energyflow.EFP(edges, measure='hadrdot', beta=1, kappa=1, normed=True, coords=None, check_input=True, ve_alg='numpy', np_optimize='greedy') Arguments edges : list Edges of the EFP graph specified by pairs of vertices. measure : { 'hadr' , 'hadrdot' , 'ee' } The choice of measure. See Measures for additional info. beta : float The parameter $\\beta$ appearing in the measure. Must be greater than zero. kappa : { float , 'pf' } If a number, the energy weighting parameter $\\kappa$. If 'pf' , use $\\kappa=v-1$ where $v$ is the valency of the vertex. normed : bool Controls normalization of the energies in the measure. coords : { 'ptyphim' , 'epxpypz' , None } Controls which coordinates are assumed for the input. See Measures for additional info. check_input : bool Whether to check the type of the input each time or assume the first input type. ve_alg : { 'numpy' , 'ef' } Which variable elimination algorithm to use. np_optimize : { True , False , 'greedy' , 'optimal' } When ve_alg='numpy' this is the optimize keyword of numpy.einsum_path . compute compute(event=None, zs=None, thetas=None) Computes the value of the EFP on a single event. Arguments event : 2-d array_like or fastjet.PseudoJet The event as an array of particles in the coordinates specified by coords . zs : 1-d array_like If present, thetas must also be present, and zs is used in place of the energies of an event. thetas : 2-d array_like If present, zs must also be present, and thetas is used in place of the pairwise angles of an event. Returns float The EFP value. batch_compute batch_compute(events, n_jobs=-1) Computes the value of the EFP on several events. Arguments events : array_like or fastjet.PseudoJet The events as an array of arrays of particles in coordinates matching those anticipated by coords . n_jobs : int The number of worker processes to use. A value of -1 will attempt to use as many processes as there are CPUs on the machine. Returns 1-d numpy.ndarray A vector of the EFP value for each event. graph graph Graph of this EFP represented by a list of edges. simple_graph simple_graph Simple graph of this EFP (forgetting all multiedges) represented by a list of edges. n n Number of vertices in the graph of this EFP. d d Degree, or number of edges, in the graph of this EFP. c c VE complexity $\\chi$ of this EFP. EFPSet A class that holds a collection of EFPs and computes their values on events. Note that all keyword arguments are stored as properties of the EFPSet instance. energyflow.EFPSet(*args, filename=None, measure='hadrdot', beta=1, kappa=1, normed=True, coords='ptyphim', check_input=True, verbose=False) EFPSet can be initialized in one of three ways (in order of precedence): Default - Use the EFPs that come installed with the EnergFlow package. Generator - Pass in a custom Generator object as the first positional argument. Custom File - Pass in the name of a .npz file saved with a custom Generator . To control which EFPs are included, EFPSet accepts an arbitrary number of specifications (see sel ) and only EFPs meeting each specification are included in the set. Arguments *args : arbitrary positional arguments If the first positional argument is a Generator instance, it is used for initialization. The remaining positional arguments must be valid arguments to sel . filename : string Path to a .npz file which has been saved by a valid energyflow.Generator . measure : { 'hadr' , 'hadr-dot' , 'ee' } See Measures for additional info. beta : float The parameter $\\beta$ appearing in the measure. Must be greater than zero. kappa : { float , 'pf' } If a number, the energy weighting parameter $\\kappa$. If 'pf' , use $\\kappa=v-1$ where $v$ is the valency of the vertex. normed : bool Controls normalization of the energies in the measure. check_type : bool Whether to check the type of the input each time or use the first input type. verbose : bool Controls printed output when initializing EFPSet. compute compute(event=None, zs=None, thetas=None) Computes the values of the stored EFPs on a single event. Arguments event : 2-d array_like or fastjet.PseudoJet The event as an array of particles in the coordinates specified by coords . zs : 1-d array_like If present, thetas must also be present, and zs is used in place of the energies of an event. thetas : 2-d array_like If present, zs must also be present, and thetas is used in place of the pairwise angles of an event. Returns 1-d numpy.ndarray A vector of the EFP values. batch_compute batch_compute(events, n_jobs=-1) Computes the value of the stored EFPs on several events. Arguments events : array_like or fastjet.PseudoJet The events as an array of arrays of particles in coordinates matching those anticipated by coords . n_jobs : int The number of worker processes to use. A value of -1 will attempt to use as many processes as there are CPUs on the machine. Returns 2-d numpy.ndarray An array of the EFP values for each event. calc_disc calc_disc(X) Computes disconnected EFPs according to the internal specifications using the connected EFPs provided as input. Arguments X : numpy.ndarray Array of connected EFPs. Rows are different events, columns are the different EFPs. Can handle a single event (a 1-dim array) as input. EFPs are assumed to be in the order expected by the instance of EFPSet ; the safest way to ensure this is to use the same EFPSet to calculate both connected and disconnected EFPs. This function is used internally in compute and batch_compute . Returns numpy.ndarray A concatenated array of the connected and disconnected EFPs. sel sel(*args) Computes a boolean mask of EFPs matching each of the specifications provided by the args . Arguments *args : arbitrary positional arguments Each argument can be either a string or a length-two iterable. If the argument is a string, it should consist of three parts: a character which is a valid element of cols , a comparison operator (one of < , > , <= , >= , == , != ), and a number. Whitespace between the parts does not matter. If the argument is a tuple, the first element should be a string containing a column header character and a comparison operator; the second element is the value to be compared. The tuple version is useful when the value is a variable that changes (such as in a list comprehension). Returns 1-d numpy.ndarray A boolean array of length the number of EFPs stored by this object. count count(*args) Counts the number of EFPs meeting the specifications of the arguments using sel . Arguments *args : arbitrary positional arguments Valid arguments to be passed to sel . Returns int The number of EFPs meeting the specifications provided. graphs graphs(*args) Graphs meeting provided specifications. Arguments *args : arbitrary positional arguments Valid arguments to be passed to sel , or, if a single integer, the index of a particular graph. Returns list , if single integer argument is given The list of edges corresponding to the specified graph 1-d numpy.ndarray , otherwise An array of graphs (as lists of edges) matching the specifications. simple_graphs simple_graphs(*args) Simple graphs meeting provided specifications. Arguments *args : arbitrary positional arguments Valid arguments to be passed to sel , or, if a single integer, the index of particular simple graph. Returns list , if single integer argument is given The list of edges corresponding to the specified simple graph 1-d numpy.ndarray , otherwise An array of simple graphs (as lists of edges) matching the specifications. specs specs An array of EFP specifications. Each row represents an EFP and the columns represent the quantities indicated by cols . cspecs cspecs Specification array for connected EFPs. cols cols Column labels for specs . Those of primary interest are listed below. n : Number of vertices. e : Number of simple edges. d : Degree, or number of multiedges. v : Maximum valency (number of edges touching a vertex). k : Unique identifier within EFPs of this (n,d). c : VE complexity $\\chi$. p : Number of prime factors (or connected components). h : Number of valency 1 vertices (a.k.a. 'hanging chads').","title":"Energy Flow Polynomials"},{"location":"docs/efp/#efp","text":"A class for representing and computing a single EFP. Note that all keyword arguments are stored as properties of the EFP instance. energyflow.EFP(edges, measure='hadrdot', beta=1, kappa=1, normed=True, coords=None, check_input=True, ve_alg='numpy', np_optimize='greedy') Arguments edges : list Edges of the EFP graph specified by pairs of vertices. measure : { 'hadr' , 'hadrdot' , 'ee' } The choice of measure. See Measures for additional info. beta : float The parameter $\\beta$ appearing in the measure. Must be greater than zero. kappa : { float , 'pf' } If a number, the energy weighting parameter $\\kappa$. If 'pf' , use $\\kappa=v-1$ where $v$ is the valency of the vertex. normed : bool Controls normalization of the energies in the measure. coords : { 'ptyphim' , 'epxpypz' , None } Controls which coordinates are assumed for the input. See Measures for additional info. check_input : bool Whether to check the type of the input each time or assume the first input type. ve_alg : { 'numpy' , 'ef' } Which variable elimination algorithm to use. np_optimize : { True , False , 'greedy' , 'optimal' } When ve_alg='numpy' this is the optimize keyword of numpy.einsum_path .","title":"EFP"},{"location":"docs/efp/#compute","text":"compute(event=None, zs=None, thetas=None) Computes the value of the EFP on a single event. Arguments event : 2-d array_like or fastjet.PseudoJet The event as an array of particles in the coordinates specified by coords . zs : 1-d array_like If present, thetas must also be present, and zs is used in place of the energies of an event. thetas : 2-d array_like If present, zs must also be present, and thetas is used in place of the pairwise angles of an event. Returns float The EFP value.","title":"compute"},{"location":"docs/efp/#batch_compute","text":"batch_compute(events, n_jobs=-1) Computes the value of the EFP on several events. Arguments events : array_like or fastjet.PseudoJet The events as an array of arrays of particles in coordinates matching those anticipated by coords . n_jobs : int The number of worker processes to use. A value of -1 will attempt to use as many processes as there are CPUs on the machine. Returns 1-d numpy.ndarray A vector of the EFP value for each event.","title":"batch_compute"},{"location":"docs/efp/#graph","text":"graph Graph of this EFP represented by a list of edges.","title":"graph"},{"location":"docs/efp/#simple_graph","text":"simple_graph Simple graph of this EFP (forgetting all multiedges) represented by a list of edges.","title":"simple_graph"},{"location":"docs/efp/#n","text":"n Number of vertices in the graph of this EFP.","title":"n"},{"location":"docs/efp/#d","text":"d Degree, or number of edges, in the graph of this EFP.","title":"d"},{"location":"docs/efp/#c","text":"c VE complexity $\\chi$ of this EFP.","title":"c"},{"location":"docs/efp/#efpset","text":"A class that holds a collection of EFPs and computes their values on events. Note that all keyword arguments are stored as properties of the EFPSet instance. energyflow.EFPSet(*args, filename=None, measure='hadrdot', beta=1, kappa=1, normed=True, coords='ptyphim', check_input=True, verbose=False) EFPSet can be initialized in one of three ways (in order of precedence): Default - Use the EFPs that come installed with the EnergFlow package. Generator - Pass in a custom Generator object as the first positional argument. Custom File - Pass in the name of a .npz file saved with a custom Generator . To control which EFPs are included, EFPSet accepts an arbitrary number of specifications (see sel ) and only EFPs meeting each specification are included in the set. Arguments *args : arbitrary positional arguments If the first positional argument is a Generator instance, it is used for initialization. The remaining positional arguments must be valid arguments to sel . filename : string Path to a .npz file which has been saved by a valid energyflow.Generator . measure : { 'hadr' , 'hadr-dot' , 'ee' } See Measures for additional info. beta : float The parameter $\\beta$ appearing in the measure. Must be greater than zero. kappa : { float , 'pf' } If a number, the energy weighting parameter $\\kappa$. If 'pf' , use $\\kappa=v-1$ where $v$ is the valency of the vertex. normed : bool Controls normalization of the energies in the measure. check_type : bool Whether to check the type of the input each time or use the first input type. verbose : bool Controls printed output when initializing EFPSet.","title":"EFPSet"},{"location":"docs/efp/#compute_1","text":"compute(event=None, zs=None, thetas=None) Computes the values of the stored EFPs on a single event. Arguments event : 2-d array_like or fastjet.PseudoJet The event as an array of particles in the coordinates specified by coords . zs : 1-d array_like If present, thetas must also be present, and zs is used in place of the energies of an event. thetas : 2-d array_like If present, zs must also be present, and thetas is used in place of the pairwise angles of an event. Returns 1-d numpy.ndarray A vector of the EFP values.","title":"compute"},{"location":"docs/efp/#batch_compute_1","text":"batch_compute(events, n_jobs=-1) Computes the value of the stored EFPs on several events. Arguments events : array_like or fastjet.PseudoJet The events as an array of arrays of particles in coordinates matching those anticipated by coords . n_jobs : int The number of worker processes to use. A value of -1 will attempt to use as many processes as there are CPUs on the machine. Returns 2-d numpy.ndarray An array of the EFP values for each event.","title":"batch_compute"},{"location":"docs/efp/#calc_disc","text":"calc_disc(X) Computes disconnected EFPs according to the internal specifications using the connected EFPs provided as input. Arguments X : numpy.ndarray Array of connected EFPs. Rows are different events, columns are the different EFPs. Can handle a single event (a 1-dim array) as input. EFPs are assumed to be in the order expected by the instance of EFPSet ; the safest way to ensure this is to use the same EFPSet to calculate both connected and disconnected EFPs. This function is used internally in compute and batch_compute . Returns numpy.ndarray A concatenated array of the connected and disconnected EFPs.","title":"calc_disc"},{"location":"docs/efp/#sel","text":"sel(*args) Computes a boolean mask of EFPs matching each of the specifications provided by the args . Arguments *args : arbitrary positional arguments Each argument can be either a string or a length-two iterable. If the argument is a string, it should consist of three parts: a character which is a valid element of cols , a comparison operator (one of < , > , <= , >= , == , != ), and a number. Whitespace between the parts does not matter. If the argument is a tuple, the first element should be a string containing a column header character and a comparison operator; the second element is the value to be compared. The tuple version is useful when the value is a variable that changes (such as in a list comprehension). Returns 1-d numpy.ndarray A boolean array of length the number of EFPs stored by this object.","title":"sel"},{"location":"docs/efp/#count","text":"count(*args) Counts the number of EFPs meeting the specifications of the arguments using sel . Arguments *args : arbitrary positional arguments Valid arguments to be passed to sel . Returns int The number of EFPs meeting the specifications provided.","title":"count"},{"location":"docs/efp/#graphs","text":"graphs(*args) Graphs meeting provided specifications. Arguments *args : arbitrary positional arguments Valid arguments to be passed to sel , or, if a single integer, the index of a particular graph. Returns list , if single integer argument is given The list of edges corresponding to the specified graph 1-d numpy.ndarray , otherwise An array of graphs (as lists of edges) matching the specifications.","title":"graphs"},{"location":"docs/efp/#simple_graphs","text":"simple_graphs(*args) Simple graphs meeting provided specifications. Arguments *args : arbitrary positional arguments Valid arguments to be passed to sel , or, if a single integer, the index of particular simple graph. Returns list , if single integer argument is given The list of edges corresponding to the specified simple graph 1-d numpy.ndarray , otherwise An array of simple graphs (as lists of edges) matching the specifications.","title":"simple_graphs"},{"location":"docs/efp/#specs","text":"specs An array of EFP specifications. Each row represents an EFP and the columns represent the quantities indicated by cols .","title":"specs"},{"location":"docs/efp/#cspecs","text":"cspecs Specification array for connected EFPs.","title":"cspecs"},{"location":"docs/efp/#cols","text":"cols Column labels for specs . Those of primary interest are listed below. n : Number of vertices. e : Number of simple edges. d : Degree, or number of multiedges. v : Maximum valency (number of edges touching a vertex). k : Unique identifier within EFPs of this (n,d). c : VE complexity $\\chi$. p : Number of prime factors (or connected components). h : Number of valency 1 vertices (a.k.a. 'hanging chads').","title":"cols"},{"location":"docs/gen/","text":"Implementation of EFP Generator class. Generator Generates non-isomorphic multigraphs according to provided specifications. energyflow.Generator(dmax=None, nmax=None, emax=None, cmax=None, vmax=None, comp_dmaxs=None, filename=None, ve_alg='numpy', np_optimize='greedy', verbose=False) Doing a fresh generation of connected multigraphs ( filename=None ) requires that igraph be installed. Arguments dmax : int The maximum number of edges of the generated connected graphs. nmax : int The maximum number of vertices of the generated connected graphs. emax : int The maximum number of edges of the generated connected simple graphs. cmax : int The maximum VE complexity $\\chi$ of the generated connected graphs. vmax : int The maximum valency of the generated connected graphs. comp_dmaxs : { dict , int } If an integer, the maximum number of edges of the generated disconnected graphs. If a dictionary, the keys are numbers of vertices and the values are the maximum number of edges of the generated disconnected graphs with that number of vertices. filename : str If None , do a complete generation from scratch. If set to a string, read in connected graphs from the file given, restrict them according to the various 'max' parameters, and do a fresh disconnected generation. The special value filename='default' means to read in graphs from the default file. This is useful when various disconnected graph parameters are to be varied since the generation of large simple graphs is the most computationlly intensive part. ve_alg : { 'numpy' , 'ef' } Which variable elimination algorithm to use. np_optimize : { True , False , 'greedy' , 'optimal' } When ve_alg='numpy' this is the optimize keyword of numpy.einsum_path . verbose : bool A flag to control printing. save save(filename) Save the current generator to file. Arguments filename : str The path to save the file. specs specs An array of EFP specifications. Each row represents an EFP and the columns represent the quantities indicated by cols .","title":"Generation"},{"location":"docs/gen/#generator","text":"Generates non-isomorphic multigraphs according to provided specifications. energyflow.Generator(dmax=None, nmax=None, emax=None, cmax=None, vmax=None, comp_dmaxs=None, filename=None, ve_alg='numpy', np_optimize='greedy', verbose=False) Doing a fresh generation of connected multigraphs ( filename=None ) requires that igraph be installed. Arguments dmax : int The maximum number of edges of the generated connected graphs. nmax : int The maximum number of vertices of the generated connected graphs. emax : int The maximum number of edges of the generated connected simple graphs. cmax : int The maximum VE complexity $\\chi$ of the generated connected graphs. vmax : int The maximum valency of the generated connected graphs. comp_dmaxs : { dict , int } If an integer, the maximum number of edges of the generated disconnected graphs. If a dictionary, the keys are numbers of vertices and the values are the maximum number of edges of the generated disconnected graphs with that number of vertices. filename : str If None , do a complete generation from scratch. If set to a string, read in connected graphs from the file given, restrict them according to the various 'max' parameters, and do a fresh disconnected generation. The special value filename='default' means to read in graphs from the default file. This is useful when various disconnected graph parameters are to be varied since the generation of large simple graphs is the most computationlly intensive part. ve_alg : { 'numpy' , 'ef' } Which variable elimination algorithm to use. np_optimize : { True , False , 'greedy' , 'optimal' } When ve_alg='numpy' this is the optimize keyword of numpy.einsum_path . verbose : bool A flag to control printing.","title":"Generator"},{"location":"docs/gen/#save","text":"save(filename) Save the current generator to file. Arguments filename : str The path to save the file.","title":"save"},{"location":"docs/gen/#specs","text":"specs An array of EFP specifications. Each row represents an EFP and the columns represent the quantities indicated by cols .","title":"specs"},{"location":"docs/measure/","text":"Energy and Angular Measures The appropriate notions of energy and angle depend on the collider context. Typically, one wants to work with observables that respect the appropriate Lorentz subgroup for the collision type of interest. EnergyFlow is capable of handling two broad classes of measures: $e^+e^-$ and hadronic, which are selected using the required measure argument. For substructure applications, it is often convenient to normalize the energies so that $\\sum_iz_i=1$. The normed keyword argument is provided to control normalization of the energies (default is True ). Each measure comes with a parameter $\\beta>0$ which controls the relative weighting between smaller and larger anglular structures. This can be set using the beta keyword argument (default is 1 ). There is also a $\\kappa$ parameter to control the relative weighting between soft and hard energies. This can be set using the kappa keyword argument (default is 1 ). Only kappa=1 yields collinear-safe observables. Beyond the measures implemented here, the user can implement their own custom measure by passing in ${z_i}$ and ${\\theta_{ij}}$ directly to the EFP classes. Hadronic Measures For hadronic collisions, observables are typically desired to be invariant under boosts along the beam direction and rotations about the beam direction. Thus, particle transverse momentum $p_T$ and rapidity-azimuth coordinates $(y,\\phi)$ are used. There are two hadronic measures implemented in EnergyFlow: 'hadr' and 'hadrdot' . These are listed explicitly below. 'hadr' : z_i=p_{T,i}^{\\kappa},\\quad\\quad \\theta_{ij}=(\\Delta y_{ij}^2 + \\Delta\\phi_{ij}^2)^{\\beta/2}. 'hadrdot' : z_i=p_{T,i}^{\\kappa},\\quad\\quad \\theta_{ij}=\\left(\\frac{2p^\\mu_ip_{j\\mu}}{p_{T,i}p_{T,j}} \\right)^{\\beta/2}. e+e- Measures For $e^+e^-$ collisions, observables are typically desired to be invariant under the full group of rotations about the interaction point. Since the center of momentum energy is known, the particle energy $E$ is typically used. For the angular measure, pairwise Lorentz contractions of the normalized particle four-momenta are used. There is one $e^+e^-$ measure implemented. 'ee' : z_i = E_{i}^{\\kappa}, \\quad\\quad \\theta_{ij} = \\left(\\frac{2p_i^\\mu p_{j \\mu}}{E_i E_j}\\right)^{\\beta/2}. Measure Class for dealing with any kind of measure. energyflow.Measure(measure, beta=1, kappa=1, normed=True, coords=None, check_input=True) Processes inputs according to the measure choice. Arguments measure : string The string specifying the energy and angular measures to use. beta : float The angular weighting exponent $\\beta$. Must be positive. kappa : { float , 'pf' } If a number, the energy weighting exponent $\\kappa$. If 'pf' , use $\\kappa=v$ where $v$ is the valency of the vertex. 'pf' cannot be used with measure 'hadr' . Only IRC-safe for kappa=1 . normed : bool Whether or not to use normalized energies. coords : { 'ptyphim' , 'epxpypz' , None } Controls which coordinates are assumed for the input. If 'ptyphim' , the fourth column (the masses) is optional and massless particles are assumed if it is not present. If None , coords with be 'ptyphim' if using a hadronic measure and 'epxpypz' if using the e+e- measaure. check_input : bool Whether to check the type of input each time or assume the first input type. evaluate evaluate(arg) Evaluate the measure on a set of particles. Arguments arg : 2-d numpy.ndarray A two-dimensional array of the particles with each row being a particle and the columns specified by the coords attribute. Returns ( 1-d numpy.ndarray , 2-d numpy.ndarray ) ( zs , thetas ) where zs is a vector of the energy fractions for each particle and thetas is the distance matrix between the particles.","title":"Measures"},{"location":"docs/measure/#energy-and-angular-measures","text":"The appropriate notions of energy and angle depend on the collider context. Typically, one wants to work with observables that respect the appropriate Lorentz subgroup for the collision type of interest. EnergyFlow is capable of handling two broad classes of measures: $e^+e^-$ and hadronic, which are selected using the required measure argument. For substructure applications, it is often convenient to normalize the energies so that $\\sum_iz_i=1$. The normed keyword argument is provided to control normalization of the energies (default is True ). Each measure comes with a parameter $\\beta>0$ which controls the relative weighting between smaller and larger anglular structures. This can be set using the beta keyword argument (default is 1 ). There is also a $\\kappa$ parameter to control the relative weighting between soft and hard energies. This can be set using the kappa keyword argument (default is 1 ). Only kappa=1 yields collinear-safe observables. Beyond the measures implemented here, the user can implement their own custom measure by passing in ${z_i}$ and ${\\theta_{ij}}$ directly to the EFP classes.","title":"Energy and Angular Measures"},{"location":"docs/measure/#hadronic-measures","text":"For hadronic collisions, observables are typically desired to be invariant under boosts along the beam direction and rotations about the beam direction. Thus, particle transverse momentum $p_T$ and rapidity-azimuth coordinates $(y,\\phi)$ are used. There are two hadronic measures implemented in EnergyFlow: 'hadr' and 'hadrdot' . These are listed explicitly below. 'hadr' : z_i=p_{T,i}^{\\kappa},\\quad\\quad \\theta_{ij}=(\\Delta y_{ij}^2 + \\Delta\\phi_{ij}^2)^{\\beta/2}. 'hadrdot' : z_i=p_{T,i}^{\\kappa},\\quad\\quad \\theta_{ij}=\\left(\\frac{2p^\\mu_ip_{j\\mu}}{p_{T,i}p_{T,j}} \\right)^{\\beta/2}.","title":"Hadronic Measures"},{"location":"docs/measure/#ee-measures","text":"For $e^+e^-$ collisions, observables are typically desired to be invariant under the full group of rotations about the interaction point. Since the center of momentum energy is known, the particle energy $E$ is typically used. For the angular measure, pairwise Lorentz contractions of the normalized particle four-momenta are used. There is one $e^+e^-$ measure implemented. 'ee' : z_i = E_{i}^{\\kappa}, \\quad\\quad \\theta_{ij} = \\left(\\frac{2p_i^\\mu p_{j \\mu}}{E_i E_j}\\right)^{\\beta/2}.","title":"e+e- Measures"},{"location":"docs/measure/#measure","text":"Class for dealing with any kind of measure. energyflow.Measure(measure, beta=1, kappa=1, normed=True, coords=None, check_input=True) Processes inputs according to the measure choice. Arguments measure : string The string specifying the energy and angular measures to use. beta : float The angular weighting exponent $\\beta$. Must be positive. kappa : { float , 'pf' } If a number, the energy weighting exponent $\\kappa$. If 'pf' , use $\\kappa=v$ where $v$ is the valency of the vertex. 'pf' cannot be used with measure 'hadr' . Only IRC-safe for kappa=1 . normed : bool Whether or not to use normalized energies. coords : { 'ptyphim' , 'epxpypz' , None } Controls which coordinates are assumed for the input. If 'ptyphim' , the fourth column (the masses) is optional and massless particles are assumed if it is not present. If None , coords with be 'ptyphim' if using a hadronic measure and 'epxpypz' if using the e+e- measaure. check_input : bool Whether to check the type of input each time or assume the first input type.","title":"Measure"},{"location":"docs/measure/#evaluate","text":"evaluate(arg) Evaluate the measure on a set of particles. Arguments arg : 2-d numpy.ndarray A two-dimensional array of the particles with each row being a particle and the columns specified by the coords attribute. Returns ( 1-d numpy.ndarray , 2-d numpy.ndarray ) ( zs , thetas ) where zs is a vector of the energy fractions for each particle and thetas is the distance matrix between the particles.","title":"evaluate"},{"location":"docs/utils/","text":"Particle Tools Tools to compute particle kinematic quantities from four-vectors, such as transverse momentum $p_T$, rapidity $y$, and azimuthal angle $\\phi$, and vice versa. ptyphims_from_p4s energyflow.ptyphims_from_p4s(p4s, phi_ref=None, keep_shape=True) Compute the [pt,y,phi,m] representation of a four-vector for each Euclidean four-vector given as input. All-zero four-vectors are removed unless keep_shape is True . Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. phi_ref : float A reference value used so that all phis will be within $\\pm\\pi$ of thie value. keep_shape : bool Flag to determine if all-zero four-vectors will be retained. This is useful for keeping the shape of an array. Returns numpy.ndarray An array of size (M,4) consisting of the transverse momentum, rapidity, azimuthal angle, and mass of each particle. If a single particle was given as input, a one-dimensional array is returned. pts_from_p4s energyflow.pts_from_p4s(p4s) Calculate the transverse momenta of a collection of four-vectors Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. Returns numpy.ndarray An M -length array consisting of the transverse momentum of each particle. If a single particle was given as input, a single float is returned. ys_from_p4s energyflow.ys_from_p4s(p4s) Calculate the rapidities of a collection of four-vectors Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. Returns numpy.ndarray An M -length array consisting of the rapidity of each particle. If a single particle was given as input, a single float is returned. phis_from_p4s energyflow.phis_from_p4s(p4s, phi_ref=None) Calculate the azimuthal angles of a collection of four-vectors. If phi_ref is not None , then phi_fix is called using this value. Otherwise, the angles are chosen to be in the inverval $[0,2\\pi]$. Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. phi_ref : float See Returns numpy.ndarray or list An M -length array consisting of the azimuthal angle of each particle. If a single particle was given as input, a single float is returned. ms_from_p4s energyflow.ms_from_p4s(p4s) Calculate the masses of a collection of four-vectors. Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. Returns numpy.ndarray An M -length array consisting of the mass of each particle. If a single particle was given as input, a single float is returned. p4s_from_ptyphims energyflow.p4s_from_ptyphims(ptyphims) Calculate Euclidean four-vectors from transverse momentum, rapidity, azimuthal angle, and (optionally) mass for each input. Arguments ptyphims : numpy.ndarray or list An array with shape (M,4) of [pT,y,phi,m] for each particle. An array with shape (M,3) is also accepted where the masses are taken to be zero. A single particle is also accepted. Returns numpy.ndarray An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. If a single particle was given as input, a single four-vector will be returned. p4s_from_ptyphis energyflow.p4s_from_ptyphis(ptyphis) Calculate Euclidean four-vectors from transverse momentum, rapidity, and azimuthal angle. Particles are taken to be massless. Arguments ptyphims : numpy.ndarray or list An array with shape (M,3) of [pT,y,phi] for each particle. A single particle is also accepted. Returns numpy.ndarray An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. If a single particle was given as input, a single four-vector will be returned. phi_fix energyflow.phi_fix(phis, phi_ref, copy=False) A function to ensure that all phi values are within $\\pi$ of phi_ref . It is assumed that all starting phi values are within $2\\pi$ of phi_ref . Arguments phis : numpy.ndarray or list One-dimensional array of phi values. phi_ref : float A reference value used so that all phis will be within $\\pm\\pi$ of this value. copy : bool Determines if phis are copied or not. If False then phis may be modified in place. Returns numpy.ndarray An array of the fixed phi values. flat_metric energyflow.flat_metric(dim) The Minkowski metric in dim spacetime dimensions in the mostly-minus convention. Arguments dim : int The number of spacetime dimensions (thought to be four in our universe). Returns 1-d numpy.ndarray A dim -length, one-dimensional (not matrix) array equal to [+1,-1,...,-1] Data Tools Functions for dealing with datasets. These are not importable from the top level energyflow module, but must instead be imported from energyflow.utils . get_examples energyflow.utils.get_examples(path='~/.energyflow', which='all', overwrite=False) Pulls examples from GitHub. To ensure availability of all examples update EnergyFlow to the latest version. Arguments path : str The destination for the downloaded files. which : { list , 'all' } List of examples to download, or the string 'all' in which case all the available examples are downloaded. overwrite : bool Whether to overwrite existing files or not. data_split energyflow.utils.data_split(*args, train=-1, val=0.0, test=0.1, shuffle=True) A function to split a dataset into train, test, and optionally validation datasets. Arguments *args : arbitrary numpy.ndarray datasets An arbitrary number of datasets, each required to have the same number of elements, as numpy arrays. train : { int , float } If a float, the fraction of elements to include in the training set. If an integer, the number of elements to include in the training set. The value -1 is special and means include the remaining part of the dataset in the training dataset after the test and (optionally) val parts have been removed val : { int , float } If a float, the fraction of elements to include in the validation set. If an integer, the number of elements to include in the validation set. The value 0 is special and means do not form a validation set. test : { int , float } If a float, the fraction of elements to include in the test set. If an integer, the number of elements to include in the test set. shuffle : bool A flag to control whether the dataset is shuffle prior to being split into parts. Returns list A list of the split datasets in train, [val], test order. If datasets X , Y , and Z were given as args (and assuming a non-zero val ), then [ X_train , X_val , X_test , Y_train , Y_val , Y_test , Z_train , Z_val , Z_test ] will be returned. to_categorical energyflow.utils.to_categorical(labels, num_classes=None) One-hot encodes class labels. Arguments labels : 1-d numpy.ndarray Labels in the range [0,num_classes) . num_classes : { int , None } The total number of classes. If None , taken to be the maximum label plus one. Returns 2-d numpy.ndarray The one-hot encoded labels. pixelate energyflow.utils.pixelate(jet, npix=33, img_width=0.8, nb_chan=1, norm=True, charged_counts_only=False) A function for creating a jet image from an array of particles. Arguments jet : numpy.ndarray An array of particles where each particle is of the form [ pt , y , phi , pid ] where the particle id column is only used if nb_chan=2 and charged_counts_only=True . npix : int The number of pixels on one edge of the jet image, which is taken to be a square. img_width : float The size of one edge of the jet image in the rapidity-azimuth plane. nb_chan : { 1 , 2 } The number of channels in the jet image. If 1 , then only a $p_T$ channel is constructed (grayscale). If 2 , then both a $p_T$ channel and a count channel are formed (color). norm : bool Whether to normalize the $p_T$ pixels to sum to 1 . charged_counts_only : bool If making a count channel, whether to only include charged particles. Requires that pid information be given. Returns 3-d numpy.ndarray The jet image as a (nb_chan, npix, npix) array. standardize energyflow.utils.standardize(*args, channels=None, copy=False, reg=10**-10) Normalizes each argument by the standard deviation of the pixels in arg[0]. The expected use case would be standardize(X_train, X_val, X_test) . Arguments *args : arbitrary numpy.ndarray datasets An arbitrary number of datasets, each required to have the same shape in all but the first axis. channels : int A list of which channels (assumed to be the second axis) to standardize. None is interpretted to mean every channel. copy : bool Whether or not to copy the input arrays before modifying them. reg : float Small parameter used to avoid dividing by zero. It's important that this be kept consistent for images used with a given model. Returns list A list of the now-standardized arguments. zero_center energyflow.utils.zero_center(args, kwargs) Subtracts the mean of arg[0] from the arguments. The expected use case would be standardize(X_train, X_val, X_test) . Arguments *args : arbitrary numpy.ndarray datasets An arbitrary number of datasets, each required to have the same shape in all but the first axis. channels : int A list of which channels (assumed to be the second axis) to zero center. None is interpretted to mean every channel. copy : bool Whether or not to copy the input arrays before modifying them. Returns list A list of the zero-centered arguments. remap_pids energyflow.utils.remap_pids(events, pid_i=3) Remaps PDG id numbers to small floats for use in a neural network. events are modified in place and nothing is returned. Arguments events : 3-d numpy.ndarray The events as an array of arrays of particles. pid_i : int The index corresponding to pid information along the last axis of events . Random Events Functions to generate random sets of four-vectors. Includes an implementation of the RAMBO algorithm for sampling uniform M-body massless phase space. Also includes other functions for various random, non-center of momentum, and non-uniform sampling. gen_random_events energyflow.gen_random_events(nevents, nparticles, dim=4, mass=0) Generate random events with a given number of particles of a given mass in a given spacetime dimension. The energy-momentum vectors have spatial components drawn randomly from [-1,+1]. These events are not guaranteed to uniformly sample phase space. Arguments nevents : int Number of events to generate. nparticles : int Number of particles in each event. dim : int Number of spacetime dimensions. mass : float Mass of the particles to generate. Returns numpy.ndarray An ( nevents , nparticles , dim ) array of events, each with nparticles particles with mass given by mass . gen_random_events_mcom energyflow.gen_random_events_mcom(nevents, nparticles, dim=4) Generate random events with a given number of massless particles in a given spacetime dimension. The total energy and momentum are made to sum to zero by making about half of the particles incoming. These events are not guaranteed to uniformly sample phase space. Arguments nevents : int Number of events to generate. nparticles : int Number of particles in each event. dim : int Number of spacetime dimensions. Returns numpy.ndarray An ( nevents , nparticles , dim ) array of events, each with nparticles massless particles whose total energy and momentum are all zero. gen_massless_phase_space energyflow.gen_massless_phase_space(nevents, nparticles, energy=1) Implementation of the RAMBO algorithm for uniformly sampling massless M-body phase space for any center of mass energies. Arguments nevents : int Number of events to generate. nparticles : int Number of particles in each event. energy : float Total center of mass energy of each event. Returns numpy.ndarray An ( nevents , nparticles , 4) array of events, each with nparticles massless particles and center of mass energy equal to energy .","title":"Utils"},{"location":"docs/utils/#particle-tools","text":"Tools to compute particle kinematic quantities from four-vectors, such as transverse momentum $p_T$, rapidity $y$, and azimuthal angle $\\phi$, and vice versa.","title":"Particle Tools"},{"location":"docs/utils/#ptyphims_from_p4s","text":"energyflow.ptyphims_from_p4s(p4s, phi_ref=None, keep_shape=True) Compute the [pt,y,phi,m] representation of a four-vector for each Euclidean four-vector given as input. All-zero four-vectors are removed unless keep_shape is True . Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. phi_ref : float A reference value used so that all phis will be within $\\pm\\pi$ of thie value. keep_shape : bool Flag to determine if all-zero four-vectors will be retained. This is useful for keeping the shape of an array. Returns numpy.ndarray An array of size (M,4) consisting of the transverse momentum, rapidity, azimuthal angle, and mass of each particle. If a single particle was given as input, a one-dimensional array is returned.","title":"ptyphims_from_p4s"},{"location":"docs/utils/#pts_from_p4s","text":"energyflow.pts_from_p4s(p4s) Calculate the transverse momenta of a collection of four-vectors Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. Returns numpy.ndarray An M -length array consisting of the transverse momentum of each particle. If a single particle was given as input, a single float is returned.","title":"pts_from_p4s"},{"location":"docs/utils/#ys_from_p4s","text":"energyflow.ys_from_p4s(p4s) Calculate the rapidities of a collection of four-vectors Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. Returns numpy.ndarray An M -length array consisting of the rapidity of each particle. If a single particle was given as input, a single float is returned.","title":"ys_from_p4s"},{"location":"docs/utils/#phis_from_p4s","text":"energyflow.phis_from_p4s(p4s, phi_ref=None) Calculate the azimuthal angles of a collection of four-vectors. If phi_ref is not None , then phi_fix is called using this value. Otherwise, the angles are chosen to be in the inverval $[0,2\\pi]$. Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. phi_ref : float See Returns numpy.ndarray or list An M -length array consisting of the azimuthal angle of each particle. If a single particle was given as input, a single float is returned.","title":"phis_from_p4s"},{"location":"docs/utils/#ms_from_p4s","text":"energyflow.ms_from_p4s(p4s) Calculate the masses of a collection of four-vectors. Arguments p4s : numpy.ndarray or list An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. A single particle as a one-dimensional array or list is also accepted. Returns numpy.ndarray An M -length array consisting of the mass of each particle. If a single particle was given as input, a single float is returned.","title":"ms_from_p4s"},{"location":"docs/utils/#p4s_from_ptyphims","text":"energyflow.p4s_from_ptyphims(ptyphims) Calculate Euclidean four-vectors from transverse momentum, rapidity, azimuthal angle, and (optionally) mass for each input. Arguments ptyphims : numpy.ndarray or list An array with shape (M,4) of [pT,y,phi,m] for each particle. An array with shape (M,3) is also accepted where the masses are taken to be zero. A single particle is also accepted. Returns numpy.ndarray An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. If a single particle was given as input, a single four-vector will be returned.","title":"p4s_from_ptyphims"},{"location":"docs/utils/#p4s_from_ptyphis","text":"energyflow.p4s_from_ptyphis(ptyphis) Calculate Euclidean four-vectors from transverse momentum, rapidity, and azimuthal angle. Particles are taken to be massless. Arguments ptyphims : numpy.ndarray or list An array with shape (M,3) of [pT,y,phi] for each particle. A single particle is also accepted. Returns numpy.ndarray An event as an (M,4) array of four-vectors [E,px,py,pz] for each particle. If a single particle was given as input, a single four-vector will be returned.","title":"p4s_from_ptyphis"},{"location":"docs/utils/#phi_fix","text":"energyflow.phi_fix(phis, phi_ref, copy=False) A function to ensure that all phi values are within $\\pi$ of phi_ref . It is assumed that all starting phi values are within $2\\pi$ of phi_ref . Arguments phis : numpy.ndarray or list One-dimensional array of phi values. phi_ref : float A reference value used so that all phis will be within $\\pm\\pi$ of this value. copy : bool Determines if phis are copied or not. If False then phis may be modified in place. Returns numpy.ndarray An array of the fixed phi values.","title":"phi_fix"},{"location":"docs/utils/#flat_metric","text":"energyflow.flat_metric(dim) The Minkowski metric in dim spacetime dimensions in the mostly-minus convention. Arguments dim : int The number of spacetime dimensions (thought to be four in our universe). Returns 1-d numpy.ndarray A dim -length, one-dimensional (not matrix) array equal to [+1,-1,...,-1]","title":"flat_metric"},{"location":"docs/utils/#data-tools","text":"Functions for dealing with datasets. These are not importable from the top level energyflow module, but must instead be imported from energyflow.utils .","title":"Data Tools"},{"location":"docs/utils/#get_examples","text":"energyflow.utils.get_examples(path='~/.energyflow', which='all', overwrite=False) Pulls examples from GitHub. To ensure availability of all examples update EnergyFlow to the latest version. Arguments path : str The destination for the downloaded files. which : { list , 'all' } List of examples to download, or the string 'all' in which case all the available examples are downloaded. overwrite : bool Whether to overwrite existing files or not.","title":"get_examples"},{"location":"docs/utils/#data_split","text":"energyflow.utils.data_split(*args, train=-1, val=0.0, test=0.1, shuffle=True) A function to split a dataset into train, test, and optionally validation datasets. Arguments *args : arbitrary numpy.ndarray datasets An arbitrary number of datasets, each required to have the same number of elements, as numpy arrays. train : { int , float } If a float, the fraction of elements to include in the training set. If an integer, the number of elements to include in the training set. The value -1 is special and means include the remaining part of the dataset in the training dataset after the test and (optionally) val parts have been removed val : { int , float } If a float, the fraction of elements to include in the validation set. If an integer, the number of elements to include in the validation set. The value 0 is special and means do not form a validation set. test : { int , float } If a float, the fraction of elements to include in the test set. If an integer, the number of elements to include in the test set. shuffle : bool A flag to control whether the dataset is shuffle prior to being split into parts. Returns list A list of the split datasets in train, [val], test order. If datasets X , Y , and Z were given as args (and assuming a non-zero val ), then [ X_train , X_val , X_test , Y_train , Y_val , Y_test , Z_train , Z_val , Z_test ] will be returned.","title":"data_split"},{"location":"docs/utils/#to_categorical","text":"energyflow.utils.to_categorical(labels, num_classes=None) One-hot encodes class labels. Arguments labels : 1-d numpy.ndarray Labels in the range [0,num_classes) . num_classes : { int , None } The total number of classes. If None , taken to be the maximum label plus one. Returns 2-d numpy.ndarray The one-hot encoded labels.","title":"to_categorical"},{"location":"docs/utils/#pixelate","text":"energyflow.utils.pixelate(jet, npix=33, img_width=0.8, nb_chan=1, norm=True, charged_counts_only=False) A function for creating a jet image from an array of particles. Arguments jet : numpy.ndarray An array of particles where each particle is of the form [ pt , y , phi , pid ] where the particle id column is only used if nb_chan=2 and charged_counts_only=True . npix : int The number of pixels on one edge of the jet image, which is taken to be a square. img_width : float The size of one edge of the jet image in the rapidity-azimuth plane. nb_chan : { 1 , 2 } The number of channels in the jet image. If 1 , then only a $p_T$ channel is constructed (grayscale). If 2 , then both a $p_T$ channel and a count channel are formed (color). norm : bool Whether to normalize the $p_T$ pixels to sum to 1 . charged_counts_only : bool If making a count channel, whether to only include charged particles. Requires that pid information be given. Returns 3-d numpy.ndarray The jet image as a (nb_chan, npix, npix) array.","title":"pixelate"},{"location":"docs/utils/#standardize","text":"energyflow.utils.standardize(*args, channels=None, copy=False, reg=10**-10) Normalizes each argument by the standard deviation of the pixels in arg[0]. The expected use case would be standardize(X_train, X_val, X_test) . Arguments *args : arbitrary numpy.ndarray datasets An arbitrary number of datasets, each required to have the same shape in all but the first axis. channels : int A list of which channels (assumed to be the second axis) to standardize. None is interpretted to mean every channel. copy : bool Whether or not to copy the input arrays before modifying them. reg : float Small parameter used to avoid dividing by zero. It's important that this be kept consistent for images used with a given model. Returns list A list of the now-standardized arguments.","title":"standardize"},{"location":"docs/utils/#zero_center","text":"energyflow.utils.zero_center(args, kwargs) Subtracts the mean of arg[0] from the arguments. The expected use case would be standardize(X_train, X_val, X_test) . Arguments *args : arbitrary numpy.ndarray datasets An arbitrary number of datasets, each required to have the same shape in all but the first axis. channels : int A list of which channels (assumed to be the second axis) to zero center. None is interpretted to mean every channel. copy : bool Whether or not to copy the input arrays before modifying them. Returns list A list of the zero-centered arguments.","title":"zero_center"},{"location":"docs/utils/#remap_pids","text":"energyflow.utils.remap_pids(events, pid_i=3) Remaps PDG id numbers to small floats for use in a neural network. events are modified in place and nothing is returned. Arguments events : 3-d numpy.ndarray The events as an array of arrays of particles. pid_i : int The index corresponding to pid information along the last axis of events .","title":"remap_pids"},{"location":"docs/utils/#random-events","text":"Functions to generate random sets of four-vectors. Includes an implementation of the RAMBO algorithm for sampling uniform M-body massless phase space. Also includes other functions for various random, non-center of momentum, and non-uniform sampling.","title":"Random Events"},{"location":"docs/utils/#gen_random_events","text":"energyflow.gen_random_events(nevents, nparticles, dim=4, mass=0) Generate random events with a given number of particles of a given mass in a given spacetime dimension. The energy-momentum vectors have spatial components drawn randomly from [-1,+1]. These events are not guaranteed to uniformly sample phase space. Arguments nevents : int Number of events to generate. nparticles : int Number of particles in each event. dim : int Number of spacetime dimensions. mass : float Mass of the particles to generate. Returns numpy.ndarray An ( nevents , nparticles , dim ) array of events, each with nparticles particles with mass given by mass .","title":"gen_random_events"},{"location":"docs/utils/#gen_random_events_mcom","text":"energyflow.gen_random_events_mcom(nevents, nparticles, dim=4) Generate random events with a given number of massless particles in a given spacetime dimension. The total energy and momentum are made to sum to zero by making about half of the particles incoming. These events are not guaranteed to uniformly sample phase space. Arguments nevents : int Number of events to generate. nparticles : int Number of particles in each event. dim : int Number of spacetime dimensions. Returns numpy.ndarray An ( nevents , nparticles , dim ) array of events, each with nparticles massless particles whose total energy and momentum are all zero.","title":"gen_random_events_mcom"},{"location":"docs/utils/#gen_massless_phase_space","text":"energyflow.gen_massless_phase_space(nevents, nparticles, energy=1) Implementation of the RAMBO algorithm for uniformly sampling massless M-body phase space for any center of mass energies. Arguments nevents : int Number of events to generate. nparticles : int Number of particles in each event. energy : float Total center of mass energy of each event. Returns numpy.ndarray An ( nevents , nparticles , 4) array of events, each with nparticles massless particles and center of mass energy equal to energy .","title":"gen_massless_phase_space"}]}